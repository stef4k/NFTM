{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "177d2e4f-2c99-45b6-90b0-f831920806eb",
   "metadata": {},
   "source": [
    "## Results Comparison\n",
    "We run the run_all_inpanting for both the cifar and celebahq datasets to identify and compare the best approaches till now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "195bd79d-2bc6-4708-9fe3-b75d2d64b088",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ[\"MKL_THREADING_LAYER\"] = \"GNU\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a62ef2-270e-43ef-b104-83f517378a1d",
   "metadata": {},
   "source": [
    "Defining the runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "887f158b-d565-45bc-85a4-ed73b0a44840",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = {\n",
    "    \"cifar_32\": {\n",
    "        \"cmd\": [\n",
    "            \"python3\", \"../drivers/run_all_inpainting.py\", \"--include_nftm\",\n",
    "            \"--train_dataset\", \"cifar\",\n",
    "            \"--benchmark\", \"cifar\",\n",
    "            \"--img_size\", \"32\",\n",
    "            \"--out\", \"out_cifar32\"\n",
    "        ],\n",
    "        \"summary_path\": \"out_cifar32/summary.json\",\n",
    "    },\n",
    "\n",
    "    \"celebahq_64\": {\n",
    "        \"cmd\": [\n",
    "            \"python3\", \"../drivers/run_all_inpainting.py\", \"--include_nftm\",\n",
    "            \"--train_dataset\", \"celebahq\",\n",
    "            \"--benchmark\", \"celebahq\",\n",
    "            \"--img_size\", \"64\",\n",
    "            \"--out\", \"out_celebahq64\"\n",
    "        ],\n",
    "        \"summary_path\": \"out_celebahq64/summary.json\",\n",
    "    }\n",
    "}\n",
    "results = {} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b44f5794-377a-4b5f-b720-8994fc548322",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running experiment: cifar_32 ===\n",
      "Using device: cuda\n",
      "Model parameters: 46479\n",
      "Epoch 001: loss=0.1608, val_psnr=21.88 dB, time=11.3s\n",
      "Epoch 002: loss=0.1012, val_psnr=23.49 dB, time=7.5s\n",
      "Epoch 003: loss=0.0863, val_psnr=24.32 dB, time=7.4s\n",
      "Epoch 004: loss=0.0780, val_psnr=24.79 dB, time=7.4s\n",
      "Epoch 005: loss=0.0727, val_psnr=25.11 dB, time=7.4s\n",
      "Epoch 006: loss=0.0689, val_psnr=25.48 dB, time=7.4s\n",
      "Epoch 007: loss=0.0661, val_psnr=25.38 dB, time=7.4s\n",
      "Epoch 008: loss=0.0638, val_psnr=25.90 dB, time=7.4s\n",
      "Epoch 009: loss=0.0620, val_psnr=26.00 dB, time=7.3s\n",
      "Epoch 010: loss=0.0603, val_psnr=26.16 dB, time=7.4s\n",
      "Epoch 011: loss=0.0590, val_psnr=26.04 dB, time=7.4s\n",
      "Epoch 012: loss=0.0578, val_psnr=26.34 dB, time=7.5s\n",
      "Epoch 013: loss=0.0568, val_psnr=26.39 dB, time=7.5s\n",
      "Epoch 014: loss=0.0560, val_psnr=26.43 dB, time=7.4s\n",
      "Epoch 015: loss=0.0551, val_psnr=26.58 dB, time=7.4s\n",
      "Epoch 016: loss=0.0545, val_psnr=26.61 dB, time=7.5s\n",
      "Epoch 017: loss=0.0538, val_psnr=26.66 dB, time=7.5s\n",
      "Epoch 018: loss=0.0531, val_psnr=26.62 dB, time=7.4s\n",
      "Epoch 019: loss=0.0524, val_psnr=26.60 dB, time=7.4s\n",
      "Epoch 020: loss=0.0519, val_psnr=26.70 dB, time=7.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/lpips/weights/v0.1/alex.pth\n",
      "Training and evaluation complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `Kernel Inception Distance` will save all extracted features in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/lpips/weights/v0.1/alex.pth\n",
      "Checkpoint: out_cifar32/unet/ckpt.pt\n",
      "Device: cuda\n",
      "Parameters: 46,479\n",
      "Seed: 0\n",
      "Metrics:\n",
      "  psnr_all: 26.7861\n",
      "  psnr_miss: 23.2666\n",
      "  ssim_all: 0.8807\n",
      "  ssim_miss: 2.1903\n",
      "  lpips_all: 0.0113\n",
      "  lpips_miss: 0.0326\n",
      "  fid: 17.7756\n",
      "  kid: 0.0104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `Kernel Inception Distance` will save all extracted features in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running TV-L1 baseline on cifar test set with 250 iterations (device=cuda)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/lpips/weights/v0.1/alex.pth\n",
      "[TVL1] mean PSNR_all=25.58 dB, PSNR_miss=21.65 dB\n",
      "Saved metrics to out_cifar32/tvl1/metrics.json\n",
      "[device] cuda | criterion=MSE\n",
      "[controller] dense | params=46375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/lpips/weights/v0.1/alex.pth\n",
      "[ep 01] β_train=0.280 K_train=5 | loss 0.1267 | train PSNR 15.22 dB | eval PSNR 1..12: 14.96, 15.32, 15.66, 15.97, 16.26 ... 17.78 | ctrl=dense | final SSIM 0.4865 | final LPIPS 0.0852\n",
      "[ep 02] β_train=0.310 K_train=6 | loss 0.1207 | train PSNR 15.44 dB | eval PSNR 1..12: 15.00, 15.40, 15.77, 16.12, 16.44 ... 18.14 | ctrl=dense | final SSIM 0.5174 | final LPIPS 0.0762\n",
      "[ep 03] β_train=0.340 K_train=7 | loss 0.1197 | train PSNR 15.49 dB | eval PSNR 1..12: 15.04, 15.48, 15.88, 16.27, 16.62 ... 18.49 | ctrl=dense | final SSIM 0.5419 | final LPIPS 0.0687\n",
      "[ep 04] β_train=0.370 K_train=8 | loss 0.1142 | train PSNR 15.71 dB | eval PSNR 1..12: 15.04, 15.51, 15.95, 16.36, 16.75 ... 18.78 | ctrl=dense | final SSIM 0.5598 | final LPIPS 0.0625\n",
      "[ep 05] β_train=0.400 K_train=8 | loss 0.1111 | train PSNR 15.85 dB | eval PSNR 1..12: 15.11, 15.61, 16.09, 16.53, 16.95 ... 19.13 | ctrl=dense | final SSIM 0.5769 | final LPIPS 0.0574\n",
      "[ep 06] β_train=0.430 K_train=8 | loss 0.1121 | train PSNR 15.81 dB | eval PSNR 1..12: 15.15, 15.69, 16.20, 16.68, 17.13 ... 19.49 | ctrl=dense | final SSIM 0.5988 | final LPIPS 0.0502\n",
      "[ep 07] β_train=0.460 K_train=8 | loss 0.1071 | train PSNR 16.04 dB | eval PSNR 1..12: 15.18, 15.76, 16.30, 16.81, 17.29 ... 19.84 | ctrl=dense | final SSIM 0.6182 | final LPIPS 0.0457\n",
      "[ep 08] β_train=0.490 K_train=8 | loss 0.1060 | train PSNR 16.09 dB | eval PSNR 1..12: 15.21, 15.82, 16.40, 16.94, 17.45 ... 20.17 | ctrl=dense | final SSIM 0.6362 | final LPIPS 0.0413\n",
      "[ep 09] β_train=0.520 K_train=8 | loss 0.1059 | train PSNR 16.11 dB | eval PSNR 1..12: 15.25, 15.90, 16.51, 17.09, 17.63 ... 20.51 | ctrl=dense | final SSIM 0.6531 | final LPIPS 0.0368\n",
      "[ep 10] β_train=0.550 K_train=8 | loss 0.1021 | train PSNR 16.29 dB | eval PSNR 1..12: 15.29, 15.98, 16.63, 17.24, 17.81 ... 20.87 | ctrl=dense | final SSIM 0.6701 | final LPIPS 0.0330\n",
      "[ep 11] β_train=0.580 K_train=8 | loss 0.1000 | train PSNR 16.40 dB | eval PSNR 1..12: 15.33, 16.05, 16.73, 17.38, 17.99 ... 21.21 | ctrl=dense | final SSIM 0.6853 | final LPIPS 0.0296\n",
      "[ep 12] β_train=0.600 K_train=8 | loss 0.0993 | train PSNR 16.42 dB | eval PSNR 1..12: 15.35, 16.09, 16.80, 17.47, 18.10 ... 21.44 | ctrl=dense | final SSIM 0.6948 | final LPIPS 0.0274\n",
      "[ep 13] β_train=0.600 K_train=8 | loss 0.0990 | train PSNR 16.43 dB | eval PSNR 1..12: 15.34, 16.08, 16.79, 17.46, 18.09 ... 21.43 | ctrl=dense | final SSIM 0.6958 | final LPIPS 0.0272\n",
      "[ep 14] β_train=0.600 K_train=8 | loss 0.0999 | train PSNR 16.39 dB | eval PSNR 1..12: 15.35, 16.09, 16.80, 17.47, 18.10 ... 21.45 | ctrl=dense | final SSIM 0.6970 | final LPIPS 0.0271\n",
      "[ep 15] β_train=0.600 K_train=8 | loss 0.1007 | train PSNR 16.35 dB | eval PSNR 1..12: 15.35, 16.09, 16.80, 17.46, 18.09 ... 21.41 | ctrl=dense | final SSIM 0.6887 | final LPIPS 0.0279\n",
      "[ep 16] β_train=0.600 K_train=8 | loss 0.0982 | train PSNR 16.47 dB | eval PSNR 1..12: 15.34, 16.09, 16.80, 17.47, 18.10 ... 21.47 | ctrl=dense | final SSIM 0.6971 | final LPIPS 0.0267\n",
      "[ep 17] β_train=0.600 K_train=8 | loss 0.1007 | train PSNR 16.36 dB | eval PSNR 1..12: 15.34, 16.08, 16.79, 17.46, 18.09 ... 21.44 | ctrl=dense | final SSIM 0.6969 | final LPIPS 0.0272\n",
      "[ep 18] β_train=0.600 K_train=8 | loss 0.0981 | train PSNR 16.50 dB | eval PSNR 1..12: 15.34, 16.08, 16.79, 17.46, 18.09 ... 21.44 | ctrl=dense | final SSIM 0.6956 | final LPIPS 0.0273\n",
      "[ep 19] β_train=0.600 K_train=8 | loss 0.0972 | train PSNR 16.54 dB | eval PSNR 1..12: 15.34, 16.08, 16.79, 17.46, 18.09 ... 21.43 | ctrl=dense | final SSIM 0.6951 | final LPIPS 0.0269\n",
      "[ep 20] β_train=0.600 K_train=8 | loss 0.0983 | train PSNR 16.49 dB | eval PSNR 1..12: 15.34, 16.08, 16.79, 17.46, 18.09 ... 21.45 | ctrl=dense | final SSIM 0.6970 | final LPIPS 0.0271\n",
      "[plot] saved step-wise psnr (eval) → out_cifar32/nftm/psnr_curve.png\n",
      "[plot] saved step-wise ssim (eval) → out_cifar32/nftm/ssim_curve.png\n",
      "[plot] saved step-wise lpips (eval) → out_cifar32/nftm/lpips_curve.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `Kernel Inception Distance` will save all extracted features in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[viz] saved per-epoch progression → out_cifar32/nftm/final/progress_epoch_final.png\n",
      "[gif] saved reconstruction GIF (GT top row, recon bottom) → out_cifar32/nftm/final/progress_epoch_final.gif\n",
      "[done] checkpoints and plots saved under: out_cifar32/nftm | controller=dense\n",
      "[metrics] saved metrics.json & psnr_curve.npy in out_cifar32/nftm | controller=dense\n",
      "[device] cuda | criterion=MSE\n",
      "[controller] dense | params=46375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/lpips/weights/v0.1/alex.pth\n",
      "[ep 01] β_train=0.280 K_train=5 | loss 0.1268 | train PSNR 15.21 dB | eval PSNR 1..30: 14.96, 15.32, 15.66, 15.97, 16.27 ... 19.29 | ctrl=dense | final SSIM 0.5718 | final LPIPS 0.0551\n",
      "[ep 02] β_train=0.310 K_train=6 | loss 0.1207 | train PSNR 15.44 dB | eval PSNR 1..30: 15.00, 15.40, 15.77, 16.12, 16.44 ... 19.84 | ctrl=dense | final SSIM 0.6125 | final LPIPS 0.0458\n",
      "[ep 03] β_train=0.340 K_train=7 | loss 0.1197 | train PSNR 15.49 dB | eval PSNR 1..30: 15.04, 15.47, 15.88, 16.26, 16.61 ... 20.29 | ctrl=dense | final SSIM 0.6264 | final LPIPS 0.0410\n",
      "[ep 04] β_train=0.370 K_train=8 | loss 0.1142 | train PSNR 15.71 dB | eval PSNR 1..30: 15.04, 15.51, 15.95, 16.36, 16.75 ... 20.81 | ctrl=dense | final SSIM 0.6662 | final LPIPS 0.0340\n",
      "[ep 05] β_train=0.400 K_train=9 | loss 0.1107 | train PSNR 15.87 dB | eval PSNR 1..30: 15.11, 15.61, 16.09, 16.53, 16.95 ... 21.25 | ctrl=dense | final SSIM 0.6876 | final LPIPS 0.0294\n",
      "[ep 06] β_train=0.430 K_train=10 | loss 0.1107 | train PSNR 15.88 dB | eval PSNR 1..30: 15.15, 15.69, 16.20, 16.68, 17.13 ... 21.87 | ctrl=dense | final SSIM 0.7128 | final LPIPS 0.0245\n",
      "[ep 07] β_train=0.460 K_train=11 | loss 0.1046 | train PSNR 16.17 dB | eval PSNR 1..30: 15.18, 15.76, 16.30, 16.81, 17.28 ... 22.31 | ctrl=dense | final SSIM 0.7270 | final LPIPS 0.0219\n",
      "[ep 08] β_train=0.490 K_train=12 | loss 0.1038 | train PSNR 16.21 dB | eval PSNR 1..30: 15.21, 15.82, 16.40, 16.94, 17.46 ... 22.74 | ctrl=dense | final SSIM 0.7488 | final LPIPS 0.0190\n",
      "[ep 09] β_train=0.520 K_train=13 | loss 0.1017 | train PSNR 16.36 dB | eval PSNR 1..30: 15.25, 15.90, 16.51, 17.09, 17.63 ... 23.27 | ctrl=dense | final SSIM 0.7677 | final LPIPS 0.0164\n",
      "[ep 10] β_train=0.550 K_train=14 | loss 0.0985 | train PSNR 16.53 dB | eval PSNR 1..30: 15.29, 15.97, 16.62, 17.23, 17.80 ... 23.73 | ctrl=dense | final SSIM 0.7744 | final LPIPS 0.0149\n",
      "[ep 11] β_train=0.580 K_train=15 | loss 0.0966 | train PSNR 16.61 dB | eval PSNR 1..30: 15.33, 16.05, 16.73, 17.38, 17.99 ... 24.17 | ctrl=dense | final SSIM 0.7986 | final LPIPS 0.0126\n",
      "[ep 12] β_train=0.600 K_train=16 | loss 0.0972 | train PSNR 16.56 dB | eval PSNR 1..30: 15.35, 16.09, 16.80, 17.46, 18.09 ... 24.56 | ctrl=dense | final SSIM 0.8077 | final LPIPS 0.0120\n",
      "[ep 13] β_train=0.600 K_train=17 | loss 0.0967 | train PSNR 16.58 dB | eval PSNR 1..30: 15.34, 16.08, 16.79, 17.45, 18.08 ... 24.35 | ctrl=dense | final SSIM 0.8023 | final LPIPS 0.0134\n",
      "[ep 14] β_train=0.600 K_train=18 | loss 0.0971 | train PSNR 16.58 dB | eval PSNR 1..30: 15.35, 16.09, 16.80, 17.47, 18.10 ... 24.62 | ctrl=dense | final SSIM 0.8109 | final LPIPS 0.0111\n",
      "[ep 15] β_train=0.600 K_train=19 | loss 0.0975 | train PSNR 16.57 dB | eval PSNR 1..30: 15.35, 16.09, 16.80, 17.47, 18.10 ... 24.46 | ctrl=dense | final SSIM 0.8058 | final LPIPS 0.0131\n",
      "[ep 16] β_train=0.600 K_train=20 | loss 0.0934 | train PSNR 16.80 dB | eval PSNR 1..30: 15.34, 16.09, 16.80, 17.47, 18.10 ... 24.65 | ctrl=dense | final SSIM 0.8107 | final LPIPS 0.0114\n",
      "[ep 17] β_train=0.600 K_train=20 | loss 0.0973 | train PSNR 16.59 dB | eval PSNR 1..30: 15.34, 16.08, 16.79, 17.46, 18.09 ... 24.61 | ctrl=dense | final SSIM 0.8108 | final LPIPS 0.0114\n",
      "[ep 18] β_train=0.600 K_train=20 | loss 0.0946 | train PSNR 16.73 dB | eval PSNR 1..30: 15.34, 16.08, 16.79, 17.46, 18.09 ... 24.63 | ctrl=dense | final SSIM 0.8112 | final LPIPS 0.0113\n",
      "[ep 19] β_train=0.600 K_train=20 | loss 0.0932 | train PSNR 16.81 dB | eval PSNR 1..30: 15.34, 16.08, 16.79, 17.46, 18.09 ... 24.66 | ctrl=dense | final SSIM 0.8119 | final LPIPS 0.0108\n",
      "[ep 20] β_train=0.600 K_train=20 | loss 0.0940 | train PSNR 16.78 dB | eval PSNR 1..30: 15.34, 16.08, 16.79, 17.46, 18.09 ... 24.65 | ctrl=dense | final SSIM 0.8109 | final LPIPS 0.0111\n",
      "[ep 21] β_train=0.600 K_train=20 | loss 0.0927 | train PSNR 16.85 dB | eval PSNR 1..30: 15.35, 16.09, 16.80, 17.47, 18.11 ... 24.65 | ctrl=dense | final SSIM 0.8108 | final LPIPS 0.0113\n",
      "[ep 22] β_train=0.600 K_train=20 | loss 0.0951 | train PSNR 16.69 dB | eval PSNR 1..30: 15.35, 16.09, 16.80, 17.47, 18.10 ... 24.54 | ctrl=dense | final SSIM 0.8045 | final LPIPS 0.0114\n",
      "[ep 23] β_train=0.600 K_train=20 | loss 0.0940 | train PSNR 16.73 dB | eval PSNR 1..30: 15.35, 16.10, 16.81, 17.48, 18.11 ... 24.65 | ctrl=dense | final SSIM 0.8116 | final LPIPS 0.0111\n",
      "[ep 24] β_train=0.600 K_train=20 | loss 0.0942 | train PSNR 16.76 dB | eval PSNR 1..30: 15.35, 16.09, 16.80, 17.47, 18.11 ... 24.68 | ctrl=dense | final SSIM 0.8126 | final LPIPS 0.0112\n",
      "[ep 25] β_train=0.600 K_train=20 | loss 0.0954 | train PSNR 16.70 dB | eval PSNR 1..30: 15.34, 16.08, 16.79, 17.46, 18.10 ... 24.66 | ctrl=dense | final SSIM 0.8128 | final LPIPS 0.0109\n",
      "[ep 26] β_train=0.600 K_train=20 | loss 0.0943 | train PSNR 16.78 dB | eval PSNR 1..30: 15.37, 16.11, 16.82, 17.49, 18.13 ... 24.75 | ctrl=dense | final SSIM 0.8143 | final LPIPS 0.0107\n",
      "[ep 27] β_train=0.600 K_train=20 | loss 0.0980 | train PSNR 16.54 dB | eval PSNR 1..30: 15.35, 16.10, 16.81, 17.48, 18.12 ... 24.72 | ctrl=dense | final SSIM 0.8132 | final LPIPS 0.0106\n",
      "[ep 28] β_train=0.600 K_train=20 | loss 0.0965 | train PSNR 16.62 dB | eval PSNR 1..30: 15.38, 16.12, 16.83, 17.51, 18.14 ... 24.75 | ctrl=dense | final SSIM 0.8142 | final LPIPS 0.0110\n",
      "[ep 29] β_train=0.600 K_train=20 | loss 0.0958 | train PSNR 16.64 dB | eval PSNR 1..30: 15.35, 16.10, 16.81, 17.48, 18.11 ... 24.65 | ctrl=dense | final SSIM 0.8119 | final LPIPS 0.0107\n",
      "[ep 30] β_train=0.600 K_train=20 | loss 0.0978 | train PSNR 16.58 dB | eval PSNR 1..30: 15.37, 16.12, 16.83, 17.50, 18.13 ... 24.75 | ctrl=dense | final SSIM 0.8150 | final LPIPS 0.0107\n",
      "[plot] saved step-wise psnr (eval) → runs/inpainting/nftm_dense/psnr_curve.png\n",
      "[plot] saved step-wise ssim (eval) → runs/inpainting/nftm_dense/ssim_curve.png\n",
      "[plot] saved step-wise lpips (eval) → runs/inpainting/nftm_dense/lpips_curve.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `Kernel Inception Distance` will save all extracted features in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[viz] saved per-epoch progression → runs/inpainting/nftm_dense/final/progress_epoch_final.png\n",
      "[gif] saved reconstruction GIF (GT top row, recon bottom) → runs/inpainting/nftm_dense/final/progress_epoch_final.gif\n",
      "[done] checkpoints and plots saved under: runs/inpainting/nftm_dense | controller=dense\n",
      "[metrics] saved metrics.json & psnr_curve.npy in runs/inpainting/nftm_dense | controller=dense\n",
      "[device] cuda | criterion=MSE\n",
      "[controller] unet | base=10 | params=46843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/lpips/weights/v0.1/alex.pth\n",
      "[ep 01] β_train=0.280 K_train=5 | loss 0.1295 | train PSNR 15.12 dB | eval PSNR 1..30: 14.93, 15.26, 15.57, 15.85, 16.12 ... 18.51 | ctrl=unet | final SSIM 0.4911 | final LPIPS 0.0658\n",
      "[ep 02] β_train=0.310 K_train=6 | loss 0.1228 | train PSNR 15.36 dB | eval PSNR 1..30: 14.99, 15.37, 15.73, 16.06, 16.37 ... 19.47 | ctrl=unet | final SSIM 0.5683 | final LPIPS 0.0520\n",
      "[ep 03] β_train=0.340 K_train=7 | loss 0.1193 | train PSNR 15.51 dB | eval PSNR 1..30: 15.03, 15.45, 15.84, 16.21, 16.55 ... 19.96 | ctrl=unet | final SSIM 0.5936 | final LPIPS 0.0446\n",
      "[ep 04] β_train=0.370 K_train=8 | loss 0.1151 | train PSNR 15.68 dB | eval PSNR 1..30: 15.02, 15.47, 15.89, 16.28, 16.64 ... 20.12 | ctrl=unet | final SSIM 0.5933 | final LPIPS 0.0426\n",
      "[ep 05] β_train=0.400 K_train=9 | loss 0.1145 | train PSNR 15.71 dB | eval PSNR 1..30: 14.95, 15.29, 15.59, 15.85, 16.08 ... 17.05 | ctrl=unet | final SSIM 0.4071 | final LPIPS 0.0806\n",
      "[ep 06] β_train=0.430 K_train=10 | loss 0.1148 | train PSNR 15.69 dB | eval PSNR 1..30: 15.07, 15.52, 15.93, 16.32, 16.66 ... 18.98 | ctrl=unet | final SSIM 0.5110 | final LPIPS 0.0509\n",
      "[ep 07] β_train=0.460 K_train=11 | loss 0.1144 | train PSNR 15.72 dB | eval PSNR 1..30: 15.05, 15.49, 15.88, 16.23, 16.54 ... 17.78 | ctrl=unet | final SSIM 0.4432 | final LPIPS 0.0723\n",
      "[ep 08] β_train=0.490 K_train=12 | loss 0.1119 | train PSNR 15.82 dB | eval PSNR 1..30: 15.08, 15.56, 16.00, 16.40, 16.75 ... 18.60 | ctrl=unet | final SSIM 0.4853 | final LPIPS 0.0697\n",
      "[ep 09] β_train=0.520 K_train=13 | loss 0.1125 | train PSNR 15.80 dB | eval PSNR 1..30: 15.05, 15.48, 15.87, 16.22, 16.54 ... 18.58 | ctrl=unet | final SSIM 0.4819 | final LPIPS 0.0642\n",
      "[ep 10] β_train=0.550 K_train=14 | loss 0.1091 | train PSNR 15.95 dB | eval PSNR 1..30: 15.12, 15.63, 16.08, 16.48, 16.84 ... 18.08 | ctrl=unet | final SSIM 0.4527 | final LPIPS 0.0712\n",
      "[ep 11] β_train=0.580 K_train=15 | loss 0.1110 | train PSNR 15.87 dB | eval PSNR 1..30: 15.13, 15.62, 16.03, 16.37, 16.63 ... 16.36 | ctrl=unet | final SSIM 0.3722 | final LPIPS 0.0912\n",
      "[ep 12] β_train=0.600 K_train=16 | loss 0.1156 | train PSNR 15.65 dB | eval PSNR 1..30: 15.10, 15.55, 15.90, 16.17, 16.36 ... 15.39 | ctrl=unet | final SSIM 0.3271 | final LPIPS 0.1147\n",
      "[ep 13] β_train=0.600 K_train=17 | loss 0.1146 | train PSNR 15.69 dB | eval PSNR 1..30: 14.87, 15.07, 15.19, 15.23, 15.22 ... 13.18 | ctrl=unet | final SSIM 0.2624 | final LPIPS 0.1682\n",
      "[ep 14] β_train=0.600 K_train=18 | loss 0.1109 | train PSNR 15.86 dB | eval PSNR 1..30: 15.18, 15.73, 16.21, 16.63, 16.98 ... 17.21 | ctrl=unet | final SSIM 0.4363 | final LPIPS 0.0653\n",
      "[ep 15] β_train=0.600 K_train=19 | loss 0.1087 | train PSNR 15.95 dB | eval PSNR 1..30: 15.18, 15.72, 16.21, 16.62, 16.97 ... 17.55 | ctrl=unet | final SSIM 0.4567 | final LPIPS 0.0584\n",
      "[ep 16] β_train=0.600 K_train=20 | loss 0.1096 | train PSNR 15.91 dB | eval PSNR 1..30: 15.16, 15.68, 16.14, 16.52, 16.83 ... 16.45 | ctrl=unet | final SSIM 0.3843 | final LPIPS 0.0851\n",
      "[ep 17] β_train=0.600 K_train=20 | loss 0.1105 | train PSNR 15.87 dB | eval PSNR 1..30: 15.00, 15.35, 15.63, 15.84, 15.98 ... 14.63 | ctrl=unet | final SSIM 0.3010 | final LPIPS 0.1328\n",
      "[ep 18] β_train=0.600 K_train=20 | loss 0.1113 | train PSNR 15.84 dB | eval PSNR 1..30: 15.15, 15.69, 16.17, 16.58, 16.93 ... 17.10 | ctrl=unet | final SSIM 0.4228 | final LPIPS 0.0780\n",
      "[ep 19] β_train=0.600 K_train=20 | loss 0.1088 | train PSNR 15.95 dB | eval PSNR 1..30: 15.17, 15.72, 16.23, 16.67, 17.06 ... 18.04 | ctrl=unet | final SSIM 0.4807 | final LPIPS 0.0575\n",
      "[ep 20] β_train=0.600 K_train=20 | loss 0.1081 | train PSNR 15.99 dB | eval PSNR 1..30: 15.18, 15.74, 16.24, 16.66, 17.01 ... 16.95 | ctrl=unet | final SSIM 0.4165 | final LPIPS 0.0729\n",
      "[ep 21] β_train=0.600 K_train=20 | loss 0.1076 | train PSNR 16.01 dB | eval PSNR 1..30: 15.20, 15.76, 16.27, 16.70, 17.05 ... 17.16 | ctrl=unet | final SSIM 0.4310 | final LPIPS 0.0711\n",
      "[ep 22] β_train=0.600 K_train=20 | loss 0.1097 | train PSNR 15.92 dB | eval PSNR 1..30: 15.16, 15.68, 16.13, 16.51, 16.81 ... 16.48 | ctrl=unet | final SSIM 0.3762 | final LPIPS 0.0816\n",
      "[ep 23] β_train=0.600 K_train=20 | loss 0.1093 | train PSNR 15.93 dB | eval PSNR 1..30: 15.19, 15.75, 16.24, 16.66, 17.02 ... 17.32 | ctrl=unet | final SSIM 0.4316 | final LPIPS 0.0765\n",
      "[ep 24] β_train=0.600 K_train=20 | loss 0.1061 | train PSNR 16.08 dB | eval PSNR 1..30: 15.11, 15.60, 16.04, 16.42, 16.74 ... 17.37 | ctrl=unet | final SSIM 0.4113 | final LPIPS 0.0798\n",
      "[ep 25] β_train=0.600 K_train=20 | loss 0.1128 | train PSNR 15.79 dB | eval PSNR 1..30: 15.11, 15.60, 16.04, 16.41, 16.72 ... 16.86 | ctrl=unet | final SSIM 0.3921 | final LPIPS 0.0992\n",
      "[ep 26] β_train=0.600 K_train=20 | loss 0.1084 | train PSNR 15.97 dB | eval PSNR 1..30: 15.18, 15.71, 16.19, 16.61, 16.97 ... 17.23 | ctrl=unet | final SSIM 0.4243 | final LPIPS 0.0679\n",
      "[ep 27] β_train=0.600 K_train=20 | loss 0.1088 | train PSNR 15.95 dB | eval PSNR 1..30: 15.18, 15.72, 16.20, 16.61, 16.94 ... 16.74 | ctrl=unet | final SSIM 0.3988 | final LPIPS 0.0855\n",
      "[ep 28] β_train=0.600 K_train=20 | loss 0.1085 | train PSNR 15.97 dB | eval PSNR 1..30: 15.22, 15.78, 16.27, 16.70, 17.06 ... 17.18 | ctrl=unet | final SSIM 0.4236 | final LPIPS 0.0671\n",
      "[ep 29] β_train=0.600 K_train=20 | loss 0.1078 | train PSNR 16.00 dB | eval PSNR 1..30: 15.17, 15.72, 16.21, 16.65, 17.03 ... 17.75 | ctrl=unet | final SSIM 0.4443 | final LPIPS 0.0779\n",
      "[ep 30] β_train=0.600 K_train=20 | loss 0.1077 | train PSNR 16.01 dB | eval PSNR 1..30: 15.17, 15.69, 16.17, 16.58, 16.95 ... 17.85 | ctrl=unet | final SSIM 0.4688 | final LPIPS 0.0665\n",
      "[plot] saved step-wise psnr (eval) → runs/inpainting/nftm_unet/psnr_curve.png\n",
      "[plot] saved step-wise ssim (eval) → runs/inpainting/nftm_unet/ssim_curve.png\n",
      "[plot] saved step-wise lpips (eval) → runs/inpainting/nftm_unet/lpips_curve.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `Kernel Inception Distance` will save all extracted features in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[viz] saved per-epoch progression → runs/inpainting/nftm_unet/final/progress_epoch_final.png\n",
      "[gif] saved reconstruction GIF (GT top row, recon bottom) → runs/inpainting/nftm_unet/final/progress_epoch_final.gif\n",
      "[done] checkpoints and plots saved under: runs/inpainting/nftm_unet | controller=unet\n",
      "[metrics] saved metrics.json & psnr_curve.npy in runs/inpainting/nftm_unet | controller=unet\n",
      "\n",
      "[stage] train_unet\n",
      ">>> /gpfs/users/balazsk/.conda/envs/nftm/bin/python3 /gpfs/workdir/balazsk/NFTM/nftm_inpaint/train_unet.py --epochs 20 --batch_size 256 --lr 0.002 --weight_decay 0.0001 --tv_weight 0.01 --seed 0 --save_dir out_cifar32/unet --base 10 --target_params 46375 --num_workers 2 --device cuda --benchmark cifar --img_size 32\n",
      "[stage] train_unet completed in 269.3s\n",
      "\n",
      "[stage] eval_unet\n",
      ">>> /gpfs/users/balazsk/.conda/envs/nftm/bin/python3 /gpfs/workdir/balazsk/NFTM/nftm_inpaint/eval_unet.py --ckpt out_cifar32/unet/ckpt.pt --batch_size 256 --num_workers 2 --seed 0 --save_dir out_cifar32/unet_eval --device cuda\n",
      "[stage] eval_unet completed in 196.0s\n",
      "\n",
      "[stage] tvl1_baseline\n",
      ">>> /gpfs/users/balazsk/.conda/envs/nftm/bin/python3 -m baselines.inpainting.tvl1_baseline --iters 250 --lam 80.0 --tvw 0.1 --tau_p 0.25 --tau_d 0.25 --batch_size 256 --num_workers 2 --seed 0 --save_dir out_cifar32/tvl1 --device cuda\n",
      "[stage] tvl1_baseline completed in 187.2s\n",
      "\n",
      "[stage] nftm\n",
      ">>> /gpfs/users/balazsk/.conda/envs/nftm/bin/python3 /gpfs/workdir/balazsk/NFTM/image_inpainting.py --save_metrics --save_dir out_cifar32/nftm --train_dataset cifar --benchmark cifar --img_size 32 --epochs 20\n",
      "[stage] nftm completed in 542.1s\n",
      "\n",
      "[stage] nftm_dense\n",
      ">>> /gpfs/users/balazsk/.conda/envs/nftm/bin/python3 /gpfs/workdir/balazsk/NFTM/image_inpainting.py --controller dense --save_dir runs/inpainting/nftm_dense --epochs 30 --K_train 20 --K_eval 30 --seed 0 --device cuda --save_metrics --train_dataset cifar --benchmark cifar --img_size 32\n",
      "[stage] nftm_dense completed in 1049.0s\n",
      "\n",
      "[stage] nftm_unet\n",
      ">>> /gpfs/users/balazsk/.conda/envs/nftm/bin/python3 /gpfs/workdir/balazsk/NFTM/image_inpainting.py --controller unet --save_dir runs/inpainting/nftm_unet --epochs 30 --K_train 20 --K_eval 30 --seed 0 --device cuda --save_metrics --train_dataset cifar --benchmark cifar --img_size 32\n",
      "[stage] nftm_unet completed in 1093.7s\n",
      "[info] summary written to out_cifar32/summary.json\n",
      "\n",
      "RESULTS\n",
      "method | psnr_all | psnr_miss | ssim_all | ssim_miss | lpips_all | lpips_miss | fid     | kid    | params    \n",
      "-------+----------+-----------+----------+-----------+-----------+------------+---------+--------+-----------\n",
      "unet   | 26.7861  | 23.2666   | 0.8807   | 2.1903    | 0.0113    | 0.0326     | 17.7756 | 0.0104 | 46479.0000\n",
      "tvl1   | 25.5758  | 21.6536   | 0.8770   | 0.8526    | 0.0124    | 0.0205     | 20.0207 | 0.0119 | -         \n",
      "nftm   | 21.4936  | 17.5573   | 0.6989   | 1.8114    | 0.0272    | 0.0889     | 90.0137 | 0.0837 | 46375.0000\n",
      "[info] NFTM summary written to runs/inpainting/summary.csv\n",
      "\n",
      "NFTM SUMMARY\n",
      "controller | psnr_all | psnr_miss | ssim_all | ssim_miss | lpips_all | lpips_miss | fid      | kid    | final_psnr\n",
      "-----------+----------+-----------+----------+-----------+-----------+------------+----------+--------+-----------\n",
      "dense      | 24.7276  | 20.8173   | 0.8138   | 2.1290    | 0.0109    | 0.0410     | 45.7054  | 0.0382 | 24.7476   \n",
      "unet       | 17.8012  | 13.8909   | 0.4663   | 1.2823    | 0.0670    | 0.2323     | 158.1003 | 0.1597 | 17.8453   \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m os.path.exists(info[\u001b[33m\"\u001b[39m\u001b[33msummary_path\u001b[39m\u001b[33m\"\u001b[39m]):\n\u001b[32m     10\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(info[\u001b[33m\"\u001b[39m\u001b[33msummary_path\u001b[39m\u001b[33m\"\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m         \u001b[43mresults\u001b[49m[name] = json.load(f)\n\u001b[32m     12\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m Loaded metrics: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minfo[\u001b[33m'\u001b[39m\u001b[33msummary_path\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mNameError\u001b[39m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "for name, info in runs.items():\n",
    "    print(f\"\\n=== Running experiment: {name} ===\")\n",
    "    try:\n",
    "        subprocess.run(info[\"cmd\"], check=True)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\" Experiment {name} failed with exit code {e.returncode}\")\n",
    "        continue\n",
    "\n",
    "    if os.path.exists(info[\"summary_path\"]):\n",
    "        with open(info[\"summary_path\"], \"r\") as f:\n",
    "            results[name] = json.load(f)\n",
    "        print(f\" Loaded metrics: {info['summary_path']}\")\n",
    "    else:\n",
    "        print(f\" No summary.json found at {info['summary_path']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146a3216-cb85-4a42-b616-c24775ac5406",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "546c2283-a6ef-43e0-9ebe-95829573fba5",
   "metadata": {},
   "source": [
    "Try to run both again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc809a36-13c9-4b29-ade3-51055dfbfaec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running experiment: cifar_32 ===\n",
      "Using device: cuda\n",
      "[Data] train_dataset=cifar, benchmark=cifar, img_size=32\n",
      "[Data] train_set size=50000\n",
      "Model parameters: 46479\n",
      "Epoch 001: loss=0.1608, val_psnr=21.92 dB, time=10.6s\n",
      "Epoch 002: loss=0.1014, val_psnr=23.37 dB, time=5.3s\n",
      "Epoch 003: loss=0.0866, val_psnr=24.28 dB, time=5.2s\n",
      "Epoch 004: loss=0.0782, val_psnr=24.77 dB, time=5.1s\n",
      "Epoch 005: loss=0.0730, val_psnr=25.15 dB, time=5.1s\n",
      "Epoch 006: loss=0.0690, val_psnr=25.49 dB, time=5.1s\n",
      "Epoch 007: loss=0.0662, val_psnr=25.49 dB, time=5.2s\n",
      "Epoch 008: loss=0.0639, val_psnr=25.89 dB, time=5.1s\n",
      "Epoch 009: loss=0.0622, val_psnr=26.03 dB, time=5.0s\n",
      "Epoch 010: loss=0.0605, val_psnr=26.09 dB, time=5.1s\n",
      "Epoch 011: loss=0.0592, val_psnr=26.12 dB, time=5.1s\n",
      "Epoch 012: loss=0.0579, val_psnr=26.31 dB, time=5.2s\n",
      "Epoch 013: loss=0.0570, val_psnr=26.43 dB, time=5.5s\n",
      "Epoch 014: loss=0.0560, val_psnr=26.42 dB, time=5.1s\n",
      "Epoch 015: loss=0.0552, val_psnr=26.64 dB, time=5.5s\n",
      "Epoch 016: loss=0.0545, val_psnr=26.68 dB, time=5.4s\n",
      "Epoch 017: loss=0.0539, val_psnr=26.57 dB, time=5.4s\n",
      "Epoch 018: loss=0.0531, val_psnr=26.66 dB, time=5.4s\n",
      "Epoch 019: loss=0.0525, val_psnr=26.61 dB, time=5.4s\n",
      "Epoch 020: loss=0.0520, val_psnr=26.62 dB, time=5.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/lpips/weights/v0.1/alex.pth\n",
      "Training and evaluation complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `Kernel Inception Distance` will save all extracted features in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Eval Data] benchmark=cifar, img_size=32\n",
      "[Eval Data] dataset size=10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/lpips/weights/v0.1/alex.pth\n",
      "Checkpoint: out_cifar32/unet/ckpt.pt\n",
      "Device: cuda\n",
      "Parameters: 46,479\n",
      "Seed: 0\n",
      "Metrics:\n",
      "  psnr_all: 26.6098\n",
      "  psnr_miss: 23.1794\n",
      "  ssim_all: 0.8714\n",
      "  ssim_miss: 2.1714\n",
      "  lpips_all: 0.0119\n",
      "  lpips_miss: 0.0339\n",
      "  fid: 19.9014\n",
      "  kid: 0.0125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `Kernel Inception Distance` will save all extracted features in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running TV-L1 baseline on cifar test set with 250 iterations (device=cuda)\n",
      "[TVL1 Eval Data] benchmark=cifar, img_size=32\n",
      "[TVL1 Eval Data] dataset size=10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/lpips/weights/v0.1/alex.pth\n",
      "[TVL1] mean PSNR_all=25.55 dB, PSNR_miss=21.64 dB\n",
      "Saved metrics to out_cifar32/tvl1/metrics.json\n",
      "[device] cuda | criterion=MSE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/gpfs/workdir/balazsk/NFTM/image_inpainting.py\", line 325, in <module>\n",
      "    main()\n",
      "  File \"/gpfs/workdir/balazsk/NFTM/image_inpainting.py\", line 96, in main\n",
      "    pyr_steps_eval = split_steps_eval(args.K_eval, pyr_sizes, args.pyr_steps if args.pyr_steps else None)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/gpfs/workdir/balazsk/NFTM/nftm_inpaint/rollout.py\", line 47, in split_steps_eval\n",
      "    assert sum(steps) == K_total and len(steps) == len(sizes), \"pyr_steps must match pyramid and sum to K_eval\"\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: pyr_steps must match pyramid and sum to K_eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[stage] train_unet\n",
      ">>> /gpfs/users/balazsk/.conda/envs/nftm/bin/python3 /gpfs/workdir/balazsk/NFTM/nftm_inpaint/train_unet.py --epochs 20 --batch_size 256 --lr 0.002 --weight_decay 0.0001 --tv_weight 0.01 --seed 0 --save_dir out_cifar32/unet --base 10 --target_params 46375 --num_workers 2 --device cuda --benchmark cifar --img_size 32 --train_dataset cifar\n",
      "[stage] train_unet completed in 221.6s\n",
      "\n",
      "[stage] eval_unet\n",
      ">>> /gpfs/users/balazsk/.conda/envs/nftm/bin/python3 /gpfs/workdir/balazsk/NFTM/nftm_inpaint/eval_unet.py --ckpt out_cifar32/unet/ckpt.pt --batch_size 256 --num_workers 2 --seed 0 --save_dir out_cifar32/unet_eval --device cuda --benchmark cifar --img_size 32\n",
      "[stage] eval_unet completed in 195.6s\n",
      "\n",
      "[stage] tvl1_baseline\n",
      ">>> /gpfs/users/balazsk/.conda/envs/nftm/bin/python3 -m baselines.inpainting.tvl1_baseline --iters 250 --lam 80.0 --tvw 0.1 --tau_p 0.25 --tau_d 0.25 --batch_size 256 --num_workers 2 --seed 0 --save_dir out_cifar32/tvl1 --device cuda --benchmark cifar --img_size 32\n",
      "[stage] tvl1_baseline completed in 189.1s\n",
      "\n",
      "[stage] nftm_pyramid\n",
      ">>> /gpfs/users/balazsk/.conda/envs/nftm/bin/python3 /gpfs/workdir/balazsk/NFTM/image_inpainting.py --controller dense --save_dir out_cifar32/nftm_dense_pyramid --epochs 30 --K_train 20 --K_eval 30 --seed 0 --device cuda --save_metrics --train_dataset cifar --benchmark cifar --img_size 32 --pyramid 16,32,64 --pyr_steps 3,10,17\n",
      "[error] command failed with exit code 1: /gpfs/users/balazsk/.conda/envs/nftm/bin/python3 /gpfs/workdir/balazsk/NFTM/image_inpainting.py --controller dense --save_dir out_cifar32/nftm_dense_pyramid --epochs 30 --K_train 20 --K_eval 30 --seed 0 --device cuda --save_metrics --train_dataset cifar --benchmark cifar --img_size 32 --pyramid 16,32,64 --pyr_steps 3,10,17\n",
      " Experiment cifar_32 failed with exit code 1\n",
      "\n",
      "=== Running experiment: celebahq_64 ===\n",
      "Using device: cuda\n",
      "[Data] train_dataset=celebahq, benchmark=celebahq, img_size=64\n",
      "[Data] train_set size=24000\n",
      "Model parameters: 46479\n",
      "Epoch 001: loss=0.1840, val_psnr=21.55 dB, time=530.9s\n",
      "Epoch 002: loss=0.1018, val_psnr=23.25 dB, time=532.3s\n",
      "Epoch 003: loss=0.0875, val_psnr=23.99 dB, time=532.9s\n",
      "Epoch 004: loss=0.0794, val_psnr=24.79 dB, time=503.1s\n",
      "Epoch 005: loss=0.0739, val_psnr=25.12 dB, time=501.7s\n",
      "Epoch 006: loss=0.0701, val_psnr=25.52 dB, time=480.7s\n",
      "Epoch 007: loss=0.0668, val_psnr=25.80 dB, time=469.4s\n",
      "Epoch 008: loss=0.0644, val_psnr=25.96 dB, time=479.8s\n",
      "Epoch 009: loss=0.0623, val_psnr=26.34 dB, time=459.6s\n",
      "Epoch 010: loss=0.0607, val_psnr=26.31 dB, time=459.8s\n",
      "Epoch 011: loss=0.0593, val_psnr=26.55 dB, time=457.9s\n",
      "Epoch 012: loss=0.0578, val_psnr=26.66 dB, time=448.6s\n",
      "Epoch 013: loss=0.0569, val_psnr=26.80 dB, time=450.6s\n",
      "Epoch 014: loss=0.0560, val_psnr=26.89 dB, time=437.4s\n",
      "Epoch 015: loss=0.0550, val_psnr=27.01 dB, time=440.6s\n",
      "Epoch 016: loss=0.0544, val_psnr=27.07 dB, time=445.0s\n",
      "Epoch 017: loss=0.0537, val_psnr=27.16 dB, time=457.1s\n",
      "Epoch 018: loss=0.0529, val_psnr=27.17 dB, time=443.4s\n",
      "Epoch 019: loss=0.0523, val_psnr=27.13 dB, time=441.6s\n",
      "Epoch 020: loss=0.0517, val_psnr=27.32 dB, time=438.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/lpips/weights/v0.1/alex.pth\n",
      "Training and evaluation complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `Kernel Inception Distance` will save all extracted features in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Eval Data] benchmark=celebahq, img_size=64\n",
      "[Eval Data] dataset size=6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/lpips/weights/v0.1/alex.pth\n",
      "Checkpoint: out_celebahq64/unet/ckpt.pt\n",
      "Device: cuda\n",
      "Parameters: 46,479\n",
      "Seed: 0\n",
      "Metrics:\n",
      "  psnr_all: 27.2737\n",
      "  psnr_miss: 24.3688\n",
      "  ssim_all: 0.8697\n",
      "  ssim_miss: 2.2628\n",
      "  lpips_all: 0.0428\n",
      "  lpips_miss: 0.1019\n",
      "  fid: 50.1084\n",
      "  kid: 0.0540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `Kernel Inception Distance` will save all extracted features in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running TV-L1 baseline on celebahq test set with 250 iterations (device=cuda)\n",
      "[TVL1 Eval Data] benchmark=celebahq, img_size=64\n",
      "[TVL1 Eval Data] dataset size=6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/lpips/weights/v0.1/alex.pth\n",
      "[TVL1] mean PSNR_all=26.69 dB, PSNR_miss=22.79 dB\n",
      "Saved metrics to out_celebahq64/tvl1/metrics.json\n",
      "[device] cuda | criterion=MSE\n",
      "[Data] train_dataset=celebahq, benchmark=celebahq, img_size=64\n",
      "[Data] train_set size=24000, test_set size=6000\n",
      "[controller] dense | params=46375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/lpips/weights/v0.1/alex.pth\n",
      "[ep 01] β_train=0.280 K_train=5 | loss 0.0306 | train PSNR 21.55 dB | eval PSNR 1..30: 18.67, 17.63, 15.86, 16.52, 16.18 ... 17.96 | ctrl=dense | final SSIM 0.4942 | final LPIPS 0.3079\n",
      "[ep 02] β_train=0.310 K_train=6 | loss 0.0275 | train PSNR 22.03 dB | eval PSNR 1..30: 18.85, 18.39, 16.72, 17.37, 16.95 ... 18.08 | ctrl=dense | final SSIM 0.5007 | final LPIPS 0.3118\n",
      "[ep 03] β_train=0.340 K_train=7 | loss 0.0230 | train PSNR 22.86 dB | eval PSNR 1..30: 19.06, 16.11, 13.71, 14.34, 13.91 ... 14.91 | ctrl=dense | final SSIM 0.3624 | final LPIPS 0.4081\n",
      "[ep 04] β_train=0.370 K_train=8 | loss 0.0200 | train PSNR 23.54 dB | eval PSNR 1..30: 18.89, 15.49, 13.20, 14.07, 13.81 ... 15.15 | ctrl=dense | final SSIM 0.3947 | final LPIPS 0.3772\n",
      "[ep 05] β_train=0.400 K_train=9 | loss 0.0193 | train PSNR 23.73 dB | eval PSNR 1..30: 18.83, 15.27, 13.05, 14.12, 14.00 ... 15.08 | ctrl=dense | final SSIM 0.3883 | final LPIPS 0.3984\n",
      "[ep 06] β_train=0.430 K_train=10 | loss 0.0184 | train PSNR 24.00 dB | eval PSNR 1..30: 18.93, 15.33, 13.11, 14.21, 14.09 ... 15.26 | ctrl=dense | final SSIM 0.4279 | final LPIPS 0.3713\n",
      "[ep 07] β_train=0.460 K_train=11 | loss 0.0180 | train PSNR 24.14 dB | eval PSNR 1..30: 18.86, 15.22, 12.98, 14.23, 14.24 ... 15.74 | ctrl=dense | final SSIM 0.4700 | final LPIPS 0.3231\n",
      "[ep 08] β_train=0.490 K_train=12 | loss 0.0171 | train PSNR 24.41 dB | eval PSNR 1..30: 18.86, 15.16, 12.93, 14.23, 14.28 ... 15.80 | ctrl=dense | final SSIM 0.5016 | final LPIPS 0.3224\n",
      "[ep 09] β_train=0.520 K_train=13 | loss 0.0168 | train PSNR 24.56 dB | eval PSNR 1..30: 18.95, 15.41, 13.20, 14.52, 14.49 ... 15.67 | ctrl=dense | final SSIM 0.5044 | final LPIPS 0.3371\n",
      "[ep 10] β_train=0.550 K_train=14 | loss 0.0161 | train PSNR 24.77 dB | eval PSNR 1..30: 18.90, 15.22, 13.01, 14.43, 14.59 ... 16.39 | ctrl=dense | final SSIM 0.5523 | final LPIPS 0.3020\n",
      "[ep 11] β_train=0.580 K_train=15 | loss 0.0171 | train PSNR 24.44 dB | eval PSNR 1..30: 18.94, 15.33, 13.12, 14.50, 14.59 ... 16.29 | ctrl=dense | final SSIM 0.5511 | final LPIPS 0.2762\n",
      "[ep 12] β_train=0.600 K_train=16 | loss 0.0165 | train PSNR 24.65 dB | eval PSNR 1..30: 18.91, 15.25, 13.04, 14.48, 14.63 ... 16.55 | ctrl=dense | final SSIM 0.5743 | final LPIPS 0.2577\n",
      "[ep 13] β_train=0.600 K_train=17 | loss 0.0159 | train PSNR 24.90 dB | eval PSNR 1..30: 18.90, 15.27, 13.06, 14.43, 14.56 ... 16.63 | ctrl=dense | final SSIM 0.5611 | final LPIPS 0.2802\n",
      "[ep 14] β_train=0.600 K_train=18 | loss 0.0160 | train PSNR 24.85 dB | eval PSNR 1..30: 18.94, 15.25, 13.01, 14.44, 14.60 ... 16.72 | ctrl=dense | final SSIM 0.5868 | final LPIPS 0.2489\n",
      "[ep 15] β_train=0.600 K_train=19 | loss 0.0154 | train PSNR 25.05 dB | eval PSNR 1..30: 18.90, 15.19, 12.95, 14.22, 14.20 ... 16.04 | ctrl=dense | final SSIM 0.5303 | final LPIPS 0.2786\n",
      "[ep 16] β_train=0.600 K_train=20 | loss 0.0166 | train PSNR 24.62 dB | eval PSNR 1..30: 18.88, 15.12, 12.92, 14.31, 14.46 ... 16.36 | ctrl=dense | final SSIM 0.5623 | final LPIPS 0.2779\n",
      "[ep 17] β_train=0.600 K_train=20 | loss 0.0156 | train PSNR 24.97 dB | eval PSNR 1..30: 18.92, 15.17, 12.96, 14.29, 14.29 ... 16.05 | ctrl=dense | final SSIM 0.5340 | final LPIPS 0.2843\n",
      "[ep 18] β_train=0.600 K_train=20 | loss 0.0162 | train PSNR 24.81 dB | eval PSNR 1..30: 18.91, 15.16, 12.97, 14.29, 14.29 ... 16.04 | ctrl=dense | final SSIM 0.5198 | final LPIPS 0.2812\n",
      "[ep 19] β_train=0.600 K_train=20 | loss 0.0154 | train PSNR 25.06 dB | eval PSNR 1..30: 18.97, 15.34, 13.10, 14.47, 14.52 ... 16.35 | ctrl=dense | final SSIM 0.5468 | final LPIPS 0.2597\n",
      "[ep 20] β_train=0.600 K_train=20 | loss 0.0156 | train PSNR 25.01 dB | eval PSNR 1..30: 18.99, 15.29, 13.06, 14.52, 14.68 ... 16.75 | ctrl=dense | final SSIM 0.5938 | final LPIPS 0.2583\n",
      "[ep 21] β_train=0.600 K_train=20 | loss 0.0157 | train PSNR 24.97 dB | eval PSNR 1..30: 18.91, 15.15, 12.92, 14.28, 14.38 ... 16.27 | ctrl=dense | final SSIM 0.5594 | final LPIPS 0.2682\n",
      "[ep 22] β_train=0.600 K_train=20 | loss 0.0152 | train PSNR 25.12 dB | eval PSNR 1..30: 18.99, 15.32, 13.06, 14.45, 14.54 ... 16.49 | ctrl=dense | final SSIM 0.5750 | final LPIPS 0.2525\n",
      "[ep 23] β_train=0.600 K_train=20 | loss 0.0156 | train PSNR 24.99 dB | eval PSNR 1..30: 18.91, 15.12, 12.93, 14.19, 14.21 ... 16.15 | ctrl=dense | final SSIM 0.5229 | final LPIPS 0.2790\n",
      "[ep 24] β_train=0.600 K_train=20 | loss 0.0160 | train PSNR 24.81 dB | eval PSNR 1..30: 19.05, 15.40, 13.13, 14.55, 14.70 ... 16.68 | ctrl=dense | final SSIM 0.5897 | final LPIPS 0.2535\n",
      "[ep 25] β_train=0.600 K_train=20 | loss 0.0157 | train PSNR 24.94 dB | eval PSNR 1..30: 19.03, 15.36, 13.10, 14.47, 14.54 ... 16.29 | ctrl=dense | final SSIM 0.5571 | final LPIPS 0.2651\n",
      "[ep 26] β_train=0.600 K_train=20 | loss 0.0156 | train PSNR 24.92 dB | eval PSNR 1..30: 19.03, 15.32, 13.05, 14.42, 14.47 ... 16.05 | ctrl=dense | final SSIM 0.5455 | final LPIPS 0.2805\n",
      "[ep 27] β_train=0.600 K_train=20 | loss 0.0154 | train PSNR 25.01 dB | eval PSNR 1..30: 18.97, 15.24, 13.01, 14.30, 14.28 ... 15.94 | ctrl=dense | final SSIM 0.5185 | final LPIPS 0.2838\n",
      "[ep 28] β_train=0.600 K_train=20 | loss 0.0165 | train PSNR 24.64 dB | eval PSNR 1..30: 18.99, 15.24, 13.03, 14.31, 14.33 ... 16.02 | ctrl=dense | final SSIM 0.5217 | final LPIPS 0.2896\n",
      "[ep 29] β_train=0.600 K_train=20 | loss 0.0150 | train PSNR 25.20 dB | eval PSNR 1..30: 19.01, 15.27, 12.98, 14.29, 14.28 ... 15.85 | ctrl=dense | final SSIM 0.5273 | final LPIPS 0.2843\n"
     ]
    }
   ],
   "source": [
    "for name, info in runs.items():\n",
    "    print(f\"\\n=== Running experiment: {name} ===\")\n",
    "    try:\n",
    "        subprocess.run(info[\"cmd\"], check=True)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\" Experiment {name} failed with exit code {e.returncode}\")\n",
    "        continue\n",
    "\n",
    "    if os.path.exists(info[\"summary_path\"]):\n",
    "        with open(info[\"summary_path\"], \"r\") as f:\n",
    "            results[name] = json.load(f)\n",
    "        print(f\" Loaded metrics: {info['summary_path']}\")\n",
    "    else:\n",
    "        print(f\" No summary.json found at {info['summary_path']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0a9678-dcab-48ff-a68e-259553b01976",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8029879-592e-44a4-980e-e0fd474b7816",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19c7c1d-bbbc-4817-b428-f513a90eeb75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1bc83cb7-9bca-4346-a601-5a91156ad84a",
   "metadata": {},
   "source": [
    "Celebahq run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bbb5563-4ebb-4845-a733-1cd373c767cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running experiment: celebahq_64 ===\n",
      "[device] cuda | criterion=MSE\n",
      "[Data] train_dataset=celebahq, benchmark=celebahq, img_size=64\n",
      "[Data] train_set size=24000, test_set size=6000\n",
      "[controller] dense | params=46375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/lpips/weights/v0.1/alex.pth\n",
      "[ep 01] β_train=0.280 K_train=5 | loss 0.0306 | train PSNR 21.55 dB | eval PSNR 1..30: 18.67, 17.63, 15.86, 16.52, 16.18 ... 17.96 | ctrl=dense | final SSIM 0.4943 | final LPIPS 0.3077\n",
      "[ep 02] β_train=0.310 K_train=6 | loss 0.0275 | train PSNR 22.03 dB | eval PSNR 1..30: 18.85, 18.39, 16.72, 17.37, 16.96 ... 18.09 | ctrl=dense | final SSIM 0.5011 | final LPIPS 0.3113\n",
      "[ep 03] β_train=0.340 K_train=7 | loss 0.0230 | train PSNR 22.86 dB | eval PSNR 1..30: 19.06, 16.05, 13.63, 14.26, 13.82 ... 14.81 | ctrl=dense | final SSIM 0.3602 | final LPIPS 0.4090\n",
      "[ep 04] β_train=0.370 K_train=8 | loss 0.0201 | train PSNR 23.53 dB | eval PSNR 1..30: 18.90, 15.49, 13.26, 14.09, 13.82 ... 15.21 | ctrl=dense | final SSIM 0.3814 | final LPIPS 0.3938\n",
      "[ep 05] β_train=0.400 K_train=9 | loss 0.0193 | train PSNR 23.74 dB | eval PSNR 1..30: 18.87, 15.30, 13.06, 14.09, 13.92 ... 15.11 | ctrl=dense | final SSIM 0.4021 | final LPIPS 0.3727\n",
      "[ep 06] β_train=0.430 K_train=10 | loss 0.0182 | train PSNR 24.04 dB | eval PSNR 1..30: 18.92, 15.31, 13.09, 14.20, 14.08 ... 15.31 | ctrl=dense | final SSIM 0.4351 | final LPIPS 0.3630\n",
      "[ep 07] β_train=0.460 K_train=11 | loss 0.0179 | train PSNR 24.17 dB | eval PSNR 1..30: 18.89, 15.23, 12.97, 14.23, 14.21 ... 15.75 | ctrl=dense | final SSIM 0.4816 | final LPIPS 0.3112\n",
      "[ep 08] β_train=0.490 K_train=12 | loss 0.0171 | train PSNR 24.41 dB | eval PSNR 1..30: 18.86, 15.13, 12.91, 14.19, 14.22 ... 15.75 | ctrl=dense | final SSIM 0.4956 | final LPIPS 0.3183\n",
      "[ep 09] β_train=0.520 K_train=13 | loss 0.0168 | train PSNR 24.55 dB | eval PSNR 1..30: 18.94, 15.34, 13.12, 14.38, 14.32 ... 15.67 | ctrl=dense | final SSIM 0.4927 | final LPIPS 0.3298\n",
      "[ep 10] β_train=0.550 K_train=14 | loss 0.0161 | train PSNR 24.78 dB | eval PSNR 1..30: 18.92, 15.26, 13.04, 14.45, 14.60 ... 16.42 | ctrl=dense | final SSIM 0.5549 | final LPIPS 0.2879\n",
      "[ep 11] β_train=0.580 K_train=15 | loss 0.0171 | train PSNR 24.45 dB | eval PSNR 1..30: 18.95, 15.31, 13.10, 14.44, 14.48 ... 16.16 | ctrl=dense | final SSIM 0.5357 | final LPIPS 0.2802\n",
      "[ep 12] β_train=0.600 K_train=16 | loss 0.0164 | train PSNR 24.66 dB | eval PSNR 1..30: 18.95, 15.32, 13.07, 14.50, 14.64 ... 16.52 | ctrl=dense | final SSIM 0.5663 | final LPIPS 0.2574\n",
      "[ep 13] β_train=0.600 K_train=17 | loss 0.0159 | train PSNR 24.89 dB | eval PSNR 1..30: 18.89, 15.27, 13.06, 14.37, 14.45 ... 16.59 | ctrl=dense | final SSIM 0.5474 | final LPIPS 0.2726\n",
      "[ep 14] β_train=0.600 K_train=18 | loss 0.0159 | train PSNR 24.86 dB | eval PSNR 1..30: 18.95, 15.26, 13.01, 14.42, 14.57 ... 16.74 | ctrl=dense | final SSIM 0.5857 | final LPIPS 0.2385\n",
      "[ep 15] β_train=0.600 K_train=19 | loss 0.0154 | train PSNR 25.04 dB | eval PSNR 1..30: 18.93, 15.23, 12.98, 14.24, 14.20 ... 16.06 | ctrl=dense | final SSIM 0.5260 | final LPIPS 0.2690\n",
      "[ep 16] β_train=0.600 K_train=20 | loss 0.0165 | train PSNR 24.63 dB | eval PSNR 1..30: 18.91, 15.17, 12.97, 14.36, 14.50 ... 16.48 | ctrl=dense | final SSIM 0.5684 | final LPIPS 0.2656\n",
      "[ep 17] β_train=0.600 K_train=20 | loss 0.0156 | train PSNR 24.97 dB | eval PSNR 1..30: 18.93, 15.17, 12.96, 14.31, 14.33 ... 16.26 | ctrl=dense | final SSIM 0.5457 | final LPIPS 0.2735\n",
      "[ep 18] β_train=0.600 K_train=20 | loss 0.0162 | train PSNR 24.83 dB | eval PSNR 1..30: 18.92, 15.17, 12.98, 14.29, 14.27 ... 16.07 | ctrl=dense | final SSIM 0.5183 | final LPIPS 0.2780\n",
      "[ep 19] β_train=0.600 K_train=20 | loss 0.0155 | train PSNR 25.05 dB | eval PSNR 1..30: 18.95, 15.31, 13.08, 14.42, 14.45 ... 16.46 | ctrl=dense | final SSIM 0.5464 | final LPIPS 0.2546\n",
      "[ep 20] β_train=0.600 K_train=20 | loss 0.0156 | train PSNR 25.01 dB | eval PSNR 1..30: 18.99, 15.28, 13.04, 14.50, 14.67 ... 17.00 | ctrl=dense | final SSIM 0.5984 | final LPIPS 0.2482\n",
      "[ep 21] β_train=0.600 K_train=20 | loss 0.0157 | train PSNR 24.96 dB | eval PSNR 1..30: 18.90, 15.14, 12.92, 14.27, 14.37 ... 16.35 | ctrl=dense | final SSIM 0.5582 | final LPIPS 0.2599\n",
      "[ep 22] β_train=0.600 K_train=20 | loss 0.0153 | train PSNR 25.10 dB | eval PSNR 1..30: 19.00, 15.32, 13.06, 14.46, 14.56 ... 16.55 | ctrl=dense | final SSIM 0.5744 | final LPIPS 0.2460\n",
      "[ep 23] β_train=0.600 K_train=20 | loss 0.0155 | train PSNR 25.00 dB | eval PSNR 1..30: 18.90, 15.10, 12.92, 14.15, 14.13 ... 16.00 | ctrl=dense | final SSIM 0.5078 | final LPIPS 0.2903\n",
      "[ep 24] β_train=0.600 K_train=20 | loss 0.0160 | train PSNR 24.80 dB | eval PSNR 1..30: 19.02, 15.36, 13.11, 14.52, 14.67 ... 16.81 | ctrl=dense | final SSIM 0.5867 | final LPIPS 0.2452\n",
      "[ep 25] β_train=0.600 K_train=20 | loss 0.0157 | train PSNR 24.94 dB | eval PSNR 1..30: 19.03, 15.37, 13.12, 14.54, 14.68 ... 16.67 | ctrl=dense | final SSIM 0.5838 | final LPIPS 0.2428\n",
      "[ep 26] β_train=0.600 K_train=20 | loss 0.0156 | train PSNR 24.93 dB | eval PSNR 1..30: 19.02, 15.33, 13.05, 14.43, 14.47 ... 16.10 | ctrl=dense | final SSIM 0.5454 | final LPIPS 0.2706\n",
      "[ep 27] β_train=0.600 K_train=20 | loss 0.0155 | train PSNR 24.99 dB | eval PSNR 1..30: 18.95, 15.21, 13.00, 14.28, 14.27 ... 16.09 | ctrl=dense | final SSIM 0.5298 | final LPIPS 0.2656\n",
      "[ep 28] β_train=0.600 K_train=20 | loss 0.0165 | train PSNR 24.64 dB | eval PSNR 1..30: 18.98, 15.22, 13.02, 14.32, 14.36 ... 16.23 | ctrl=dense | final SSIM 0.5374 | final LPIPS 0.2720\n",
      "[ep 29] β_train=0.600 K_train=20 | loss 0.0149 | train PSNR 25.22 dB | eval PSNR 1..30: 19.05, 15.37, 13.12, 14.45, 14.43 ... 16.04 | ctrl=dense | final SSIM 0.5314 | final LPIPS 0.2706\n",
      "[ep 30] β_train=0.600 K_train=20 | loss 0.0162 | train PSNR 24.78 dB | eval PSNR 1..30: 19.04, 15.35, 13.11, 14.42, 14.47 ... 16.31 | ctrl=dense | final SSIM 0.5438 | final LPIPS 0.2634\n",
      "[plot] saved step-wise psnr (eval) → out_celebahq64/nftm_dense_pyramid/psnr_curve.png\n",
      "[plot] saved step-wise ssim (eval) → out_celebahq64/nftm_dense_pyramid/ssim_curve.png\n",
      "[plot] saved step-wise lpips (eval) → out_celebahq64/nftm_dense_pyramid/lpips_curve.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `Kernel Inception Distance` will save all extracted features in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[viz] saved per-epoch progression → out_celebahq64/nftm_dense_pyramid/final/progress_epoch_final.png\n",
      "[gif] saved reconstruction GIF (GT top row, recon bottom) → out_celebahq64/nftm_dense_pyramid/final/progress_epoch_final.gif\n",
      "[done] checkpoints and plots saved under: out_celebahq64/nftm_dense_pyramid | controller=dense\n",
      "[metrics] saved metrics.json & psnr_curve.npy in out_celebahq64/nftm_dense_pyramid | controller=dense\n",
      "Using device: cuda\n",
      "[Data] train_dataset=celebahq, benchmark=celebahq, img_size=64\n",
      "[Data] train_set size=24000\n",
      "Model parameters: 46479\n",
      "Epoch 001: loss=0.1840, val_psnr=21.55 dB, time=264.4s\n",
      "Epoch 002: loss=0.1017, val_psnr=23.26 dB, time=270.9s\n",
      "Epoch 003: loss=0.0875, val_psnr=23.99 dB, time=288.2s\n",
      "Epoch 004: loss=0.0793, val_psnr=24.79 dB, time=221.8s\n",
      "Epoch 005: loss=0.0738, val_psnr=25.14 dB, time=259.8s\n",
      "Epoch 006: loss=0.0701, val_psnr=25.50 dB, time=215.1s\n",
      "Epoch 007: loss=0.0668, val_psnr=25.78 dB, time=161.6s\n",
      "Epoch 008: loss=0.0644, val_psnr=26.02 dB, time=101.0s\n",
      "Epoch 009: loss=0.0623, val_psnr=26.33 dB, time=56.0s\n",
      "Epoch 010: loss=0.0608, val_psnr=26.37 dB, time=48.4s\n",
      "Epoch 011: loss=0.0593, val_psnr=26.55 dB, time=55.6s\n",
      "Epoch 012: loss=0.0579, val_psnr=26.68 dB, time=47.1s\n",
      "Epoch 013: loss=0.0570, val_psnr=26.81 dB, time=45.7s\n",
      "Epoch 014: loss=0.0559, val_psnr=26.79 dB, time=45.2s\n",
      "Epoch 015: loss=0.0551, val_psnr=26.99 dB, time=45.2s\n",
      "Epoch 016: loss=0.0545, val_psnr=27.12 dB, time=45.1s\n",
      "Epoch 017: loss=0.0537, val_psnr=27.15 dB, time=45.5s\n",
      "Epoch 018: loss=0.0530, val_psnr=27.15 dB, time=45.6s\n",
      "Epoch 019: loss=0.0523, val_psnr=27.17 dB, time=44.9s\n",
      "Epoch 020: loss=0.0517, val_psnr=27.32 dB, time=45.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/lpips/weights/v0.1/alex.pth\n",
      "Training and evaluation complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `Kernel Inception Distance` will save all extracted features in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Eval Data] benchmark=celebahq, img_size=64\n",
      "[Eval Data] dataset size=6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/lpips/weights/v0.1/alex.pth\n",
      "Checkpoint: out_celebahq64/unet/ckpt.pt\n",
      "Device: cuda\n",
      "Parameters: 46,479\n",
      "Seed: 0\n",
      "Metrics:\n",
      "  psnr_all: 27.2716\n",
      "  psnr_miss: 24.3384\n",
      "  ssim_all: 0.8685\n",
      "  ssim_miss: 2.2602\n",
      "  lpips_all: 0.0434\n",
      "  lpips_miss: 0.1049\n",
      "  fid: 51.1562\n",
      "  kid: 0.0550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `Kernel Inception Distance` will save all extracted features in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running TV-L1 baseline on celebahq test set with 250 iterations (device=cuda)\n",
      "[TVL1 Eval Data] benchmark=celebahq, img_size=64\n",
      "[TVL1 Eval Data] dataset size=6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/lpips/weights/v0.1/alex.pth\n",
      "[TVL1] mean PSNR_all=26.69 dB, PSNR_miss=22.79 dB\n",
      "Saved metrics to out_celebahq64/tvl1/metrics.json\n",
      "[device] cuda | criterion=MSE\n",
      "[Data] train_dataset=celebahq, benchmark=celebahq, img_size=64\n",
      "[Data] train_set size=24000, test_set size=6000\n",
      "[controller] dense | params=46375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/lpips/weights/v0.1/alex.pth\n",
      "[ep 01] β_train=0.280 K_train=5 | loss 0.1584 | train PSNR 14.21 dB | eval PSNR 1..12: 13.98, 14.30, 14.60, 14.87, 15.13 ... 16.42 | ctrl=dense | final SSIM 0.3568 | final LPIPS 0.5252\n",
      "[ep 02] β_train=0.310 K_train=6 | loss 0.1498 | train PSNR 14.47 dB | eval PSNR 1..12: 14.05, 14.41, 14.76, 15.08, 15.38 ... 16.99 | ctrl=dense | final SSIM 0.4131 | final LPIPS 0.4645\n",
      "[ep 03] β_train=0.340 K_train=7 | loss 0.1460 | train PSNR 14.59 dB | eval PSNR 1..12: 14.08, 14.48, 14.85, 15.21, 15.54 ... 17.31 | ctrl=dense | final SSIM 0.4360 | final LPIPS 0.4290\n",
      "[ep 04] β_train=0.370 K_train=8 | loss 0.1420 | train PSNR 14.72 dB | eval PSNR 1..12: 14.08, 14.52, 14.92, 15.31, 15.67 ... 17.59 | ctrl=dense | final SSIM 0.4545 | final LPIPS 0.4013\n",
      "[ep 05] β_train=0.400 K_train=8 | loss 0.1436 | train PSNR 14.67 dB | eval PSNR 1..12: 14.14, 14.60, 15.04, 15.46, 15.85 ... 17.97 | ctrl=dense | final SSIM 0.4776 | final LPIPS 0.3672\n",
      "[ep 06] β_train=0.430 K_train=8 | loss 0.1380 | train PSNR 14.87 dB | eval PSNR 1..12: 14.16, 14.66, 15.13, 15.57, 15.99 ... 18.25 | ctrl=dense | final SSIM 0.4835 | final LPIPS 0.3418\n",
      "[ep 07] β_train=0.460 K_train=8 | loss 0.1346 | train PSNR 14.99 dB | eval PSNR 1..12: 14.20, 14.74, 15.24, 15.72, 16.18 ... 18.64 | ctrl=dense | final SSIM 0.5141 | final LPIPS 0.3107\n",
      "[ep 08] β_train=0.490 K_train=8 | loss 0.1327 | train PSNR 15.06 dB | eval PSNR 1..12: 14.23, 14.80, 15.34, 15.85, 16.33 ... 18.97 | ctrl=dense | final SSIM 0.5305 | final LPIPS 0.2894\n",
      "[ep 09] β_train=0.520 K_train=8 | loss 0.1296 | train PSNR 15.18 dB | eval PSNR 1..12: 14.28, 14.88, 15.45, 16.00, 16.51 ... 19.31 | ctrl=dense | final SSIM 0.5488 | final LPIPS 0.2667\n",
      "[ep 10] β_train=0.550 K_train=8 | loss 0.1230 | train PSNR 15.43 dB | eval PSNR 1..12: 14.31, 14.94, 15.55, 16.13, 16.67 ... 19.67 | ctrl=dense | final SSIM 0.5647 | final LPIPS 0.2426\n",
      "[ep 11] β_train=0.580 K_train=8 | loss 0.1310 | train PSNR 15.13 dB | eval PSNR 1..12: 14.33, 15.00, 15.64, 16.25, 16.83 ... 20.01 | ctrl=dense | final SSIM 0.5799 | final LPIPS 0.2235\n",
      "[ep 12] β_train=0.600 K_train=8 | loss 0.1240 | train PSNR 15.40 dB | eval PSNR 1..12: 14.36, 15.05, 15.71, 16.34, 16.95 ... 20.22 | ctrl=dense | final SSIM 0.5896 | final LPIPS 0.2149\n",
      "[ep 13] β_train=0.600 K_train=8 | loss 0.1215 | train PSNR 15.50 dB | eval PSNR 1..12: 14.35, 15.04, 15.70, 16.34, 16.94 ... 20.24 | ctrl=dense | final SSIM 0.5912 | final LPIPS 0.2102\n",
      "[ep 14] β_train=0.600 K_train=8 | loss 0.1226 | train PSNR 15.47 dB | eval PSNR 1..12: 14.38, 15.07, 15.73, 16.37, 16.97 ... 20.30 | ctrl=dense | final SSIM 0.5932 | final LPIPS 0.2082\n",
      "[ep 15] β_train=0.600 K_train=8 | loss 0.1214 | train PSNR 15.50 dB | eval PSNR 1..12: 14.35, 15.04, 15.70, 16.34, 16.94 ... 20.26 | ctrl=dense | final SSIM 0.5897 | final LPIPS 0.2131\n",
      "[ep 16] β_train=0.600 K_train=8 | loss 0.1255 | train PSNR 15.34 dB | eval PSNR 1..12: 14.37, 15.06, 15.72, 16.36, 16.96 ... 20.28 | ctrl=dense | final SSIM 0.5933 | final LPIPS 0.2093\n",
      "[ep 17] β_train=0.600 K_train=8 | loss 0.1217 | train PSNR 15.50 dB | eval PSNR 1..12: 14.37, 15.06, 15.72, 16.36, 16.96 ... 20.26 | ctrl=dense | final SSIM 0.5929 | final LPIPS 0.2088\n",
      "[ep 18] β_train=0.600 K_train=8 | loss 0.1278 | train PSNR 15.26 dB | eval PSNR 1..12: 14.39, 15.08, 15.74, 16.37, 16.98 ... 20.31 | ctrl=dense | final SSIM 0.5931 | final LPIPS 0.2099\n",
      "[ep 19] β_train=0.600 K_train=8 | loss 0.1218 | train PSNR 15.51 dB | eval PSNR 1..12: 14.36, 15.05, 15.72, 16.35, 16.96 ... 20.30 | ctrl=dense | final SSIM 0.5939 | final LPIPS 0.2063\n",
      "[ep 20] β_train=0.600 K_train=8 | loss 0.1240 | train PSNR 15.42 dB | eval PSNR 1..12: 14.37, 15.07, 15.73, 16.37, 16.97 ... 20.27 | ctrl=dense | final SSIM 0.5939 | final LPIPS 0.2076\n",
      "[plot] saved step-wise psnr (eval) → out_celebahq64/nftm/psnr_curve.png\n",
      "[plot] saved step-wise ssim (eval) → out_celebahq64/nftm/ssim_curve.png\n",
      "[plot] saved step-wise lpips (eval) → out_celebahq64/nftm/lpips_curve.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `Kernel Inception Distance` will save all extracted features in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[viz] saved per-epoch progression → out_celebahq64/nftm/final/progress_epoch_final.png\n",
      "[gif] saved reconstruction GIF (GT top row, recon bottom) → out_celebahq64/nftm/final/progress_epoch_final.gif\n",
      "[done] checkpoints and plots saved under: out_celebahq64/nftm | controller=dense\n",
      "[metrics] saved metrics.json & psnr_curve.npy in out_celebahq64/nftm | controller=dense\n",
      "[device] cuda | criterion=MSE\n",
      "[Data] train_dataset=celebahq, benchmark=celebahq, img_size=64\n",
      "[Data] train_set size=24000, test_set size=6000\n",
      "[controller] dense | params=46375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/lpips/weights/v0.1/alex.pth\n",
      "[ep 01] β_train=0.280 K_train=5 | loss 0.1584 | train PSNR 14.21 dB | eval PSNR 1..30: 13.98, 14.30, 14.60, 14.87, 15.13 ... 17.58 | ctrl=dense | final SSIM 0.3972 | final LPIPS 0.4302\n",
      "[ep 02] β_train=0.310 K_train=6 | loss 0.1498 | train PSNR 14.47 dB | eval PSNR 1..30: 14.05, 14.41, 14.76, 15.08, 15.38 ... 18.59 | ctrl=dense | final SSIM 0.4891 | final LPIPS 0.3380\n",
      "[ep 03] β_train=0.340 K_train=7 | loss 0.1460 | train PSNR 14.59 dB | eval PSNR 1..30: 14.08, 14.48, 14.85, 15.21, 15.54 ... 19.09 | ctrl=dense | final SSIM 0.5227 | final LPIPS 0.2916\n",
      "[ep 04] β_train=0.370 K_train=8 | loss 0.1420 | train PSNR 14.72 dB | eval PSNR 1..30: 14.08, 14.52, 14.92, 15.31, 15.67 ... 19.50 | ctrl=dense | final SSIM 0.5478 | final LPIPS 0.2587\n",
      "[ep 05] β_train=0.400 K_train=9 | loss 0.1425 | train PSNR 14.72 dB | eval PSNR 1..30: 14.14, 14.60, 15.04, 15.46, 15.85 ... 20.05 | ctrl=dense | final SSIM 0.5713 | final LPIPS 0.2241\n",
      "[ep 06] β_train=0.430 K_train=10 | loss 0.1364 | train PSNR 14.93 dB | eval PSNR 1..30: 14.16, 14.66, 15.13, 15.58, 16.01 ... 20.66 | ctrl=dense | final SSIM 0.6025 | final LPIPS 0.1916\n",
      "[ep 07] β_train=0.460 K_train=11 | loss 0.1321 | train PSNR 15.10 dB | eval PSNR 1..30: 14.20, 14.73, 15.24, 15.72, 16.17 ... 21.17 | ctrl=dense | final SSIM 0.6198 | final LPIPS 0.1654\n",
      "[ep 08] β_train=0.490 K_train=12 | loss 0.1295 | train PSNR 15.19 dB | eval PSNR 1..30: 14.23, 14.80, 15.34, 15.85, 16.33 ... 21.63 | ctrl=dense | final SSIM 0.6502 | final LPIPS 0.1461\n",
      "[ep 09] β_train=0.520 K_train=13 | loss 0.1253 | train PSNR 15.38 dB | eval PSNR 1..30: 14.28, 14.87, 15.44, 15.99, 16.50 ... 22.13 | ctrl=dense | final SSIM 0.6647 | final LPIPS 0.1229\n",
      "[ep 10] β_train=0.550 K_train=14 | loss 0.1215 | train PSNR 15.51 dB | eval PSNR 1..30: 14.31, 14.94, 15.55, 16.12, 16.67 ... 22.65 | ctrl=dense | final SSIM 0.6920 | final LPIPS 0.1052\n",
      "[ep 11] β_train=0.580 K_train=15 | loss 0.1322 | train PSNR 15.13 dB | eval PSNR 1..30: 14.01, 14.29, 14.50, 14.64, 14.73 ... 13.41 | ctrl=dense | final SSIM 0.2473 | final LPIPS 0.6614\n",
      "[ep 12] β_train=0.600 K_train=16 | loss 0.1537 | train PSNR 14.34 dB | eval PSNR 1..30: 13.99, 14.30, 14.58, 14.82, 15.02 ... 15.76 | ctrl=dense | final SSIM 0.3044 | final LPIPS 0.5373\n",
      "[ep 13] β_train=0.600 K_train=17 | loss 0.1476 | train PSNR 14.54 dB | eval PSNR 1..30: 14.01, 14.34, 14.63, 14.88, 15.09 ... 15.66 | ctrl=dense | final SSIM 0.2942 | final LPIPS 0.5361\n",
      "[ep 14] β_train=0.600 K_train=18 | loss 0.1478 | train PSNR 14.53 dB | eval PSNR 1..30: 14.02, 14.33, 14.59, 14.80, 14.97 ... 14.73 | ctrl=dense | final SSIM 0.2575 | final LPIPS 0.6470\n",
      "[ep 15] β_train=0.600 K_train=19 | loss 0.1448 | train PSNR 14.63 dB | eval PSNR 1..30: 14.05, 14.41, 14.71, 14.98, 15.20 ... 16.18 | ctrl=dense | final SSIM 0.3200 | final LPIPS 0.4975\n",
      "[ep 16] β_train=0.600 K_train=20 | loss 0.1463 | train PSNR 14.58 dB | eval PSNR 1..30: 14.09, 14.47, 14.80, 15.08, 15.32 ... 16.47 | ctrl=dense | final SSIM 0.3368 | final LPIPS 0.4837\n",
      "[ep 17] β_train=0.600 K_train=20 | loss 0.1384 | train PSNR 14.85 dB | eval PSNR 1..30: 14.13, 14.53, 14.85, 15.09, 15.27 ... 14.40 | ctrl=dense | final SSIM 0.2727 | final LPIPS 0.5402\n",
      "[ep 18] β_train=0.600 K_train=20 | loss 0.1444 | train PSNR 14.64 dB | eval PSNR 1..30: 14.16, 14.58, 14.93, 15.19, 15.39 ... 14.68 | ctrl=dense | final SSIM 0.2868 | final LPIPS 0.5180\n",
      "[ep 19] β_train=0.600 K_train=20 | loss 0.1434 | train PSNR 14.68 dB | eval PSNR 1..30: 13.82, 13.91, 13.92, 13.87, 13.79 ... 11.62 | ctrl=dense | final SSIM 0.1845 | final LPIPS 0.8167\n",
      "[ep 20] β_train=0.600 K_train=20 | loss 0.1744 | train PSNR 13.78 dB | eval PSNR 1..30: 13.83, 13.91, 13.93, 13.88, 13.79 ... 11.62 | ctrl=dense | final SSIM 0.1847 | final LPIPS 0.8171\n",
      "[ep 21] β_train=0.600 K_train=20 | loss 0.1737 | train PSNR 13.79 dB | eval PSNR 1..30: 13.80, 13.90, 13.92, 13.88, 13.80 ... 11.77 | ctrl=dense | final SSIM 0.1847 | final LPIPS 0.8083\n",
      "[ep 22] β_train=0.600 K_train=20 | loss 0.1637 | train PSNR 14.06 dB | eval PSNR 1..30: 13.94, 14.14, 14.27, 14.32, 14.32 ... 12.53 | ctrl=dense | final SSIM 0.2273 | final LPIPS 0.6349\n",
      "[ep 23] β_train=0.600 K_train=20 | loss 0.1534 | train PSNR 14.35 dB | eval PSNR 1..30: 14.01, 14.30, 14.50, 14.63, 14.70 ... 13.22 | ctrl=dense | final SSIM 0.2447 | final LPIPS 0.6352\n",
      "[ep 24] β_train=0.600 K_train=20 | loss 0.1547 | train PSNR 14.31 dB | eval PSNR 1..30: 14.02, 14.31, 14.53, 14.67, 14.75 ... 13.32 | ctrl=dense | final SSIM 0.2545 | final LPIPS 0.6141\n",
      "[ep 25] β_train=0.600 K_train=20 | loss 0.1547 | train PSNR 14.31 dB | eval PSNR 1..30: 13.91, 14.07, 14.16, 14.18, 14.15 ... 12.19 | ctrl=dense | final SSIM 0.1927 | final LPIPS 0.7864\n",
      "[ep 26] β_train=0.600 K_train=20 | loss 0.1699 | train PSNR 13.92 dB | eval PSNR 1..30: 14.17, 14.62, 14.98, 15.27, 15.49 ... 14.73 | ctrl=dense | final SSIM 0.2850 | final LPIPS 0.5581\n",
      "[ep 27] β_train=0.600 K_train=20 | loss 0.1370 | train PSNR 14.89 dB | eval PSNR 1..30: 14.23, 14.75, 15.20, 15.58, 15.89 ... 15.77 | ctrl=dense | final SSIM 0.3143 | final LPIPS 0.4739\n",
      "[ep 28] β_train=0.600 K_train=20 | loss 0.1379 | train PSNR 14.87 dB | eval PSNR 1..30: 14.26, 14.79, 15.25, 15.64, 15.96 ... 15.89 | ctrl=dense | final SSIM 0.3168 | final LPIPS 0.4703\n",
      "[ep 29] β_train=0.600 K_train=20 | loss 0.1317 | train PSNR 15.09 dB | eval PSNR 1..30: 14.22, 14.72, 15.14, 15.50, 15.80 ... 15.75 | ctrl=dense | final SSIM 0.3044 | final LPIPS 0.4914\n",
      "[ep 30] β_train=0.600 K_train=20 | loss 0.1377 | train PSNR 14.88 dB | eval PSNR 1..30: 14.23, 14.76, 15.23, 15.63, 15.95 ... 16.02 | ctrl=dense | final SSIM 0.3147 | final LPIPS 0.4753\n",
      "[plot] saved step-wise psnr (eval) → runs/inpainting/nftm_dense/psnr_curve.png\n",
      "[plot] saved step-wise ssim (eval) → runs/inpainting/nftm_dense/ssim_curve.png\n",
      "[plot] saved step-wise lpips (eval) → runs/inpainting/nftm_dense/lpips_curve.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `Kernel Inception Distance` will save all extracted features in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[viz] saved per-epoch progression → runs/inpainting/nftm_dense/final/progress_epoch_final.png\n",
      "[gif] saved reconstruction GIF (GT top row, recon bottom) → runs/inpainting/nftm_dense/final/progress_epoch_final.gif\n",
      "[done] checkpoints and plots saved under: runs/inpainting/nftm_dense | controller=dense\n",
      "[metrics] saved metrics.json & psnr_curve.npy in runs/inpainting/nftm_dense | controller=dense\n",
      "[device] cuda | criterion=MSE\n",
      "[Data] train_dataset=celebahq, benchmark=celebahq, img_size=64\n",
      "[Data] train_set size=24000, test_set size=6000\n",
      "[controller] unet | base=10 | params=46843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/lpips/weights/v0.1/alex.pth\n",
      "[ep 01] β_train=0.280 K_train=5 | loss 0.1578 | train PSNR 14.23 dB | eval PSNR 1..30: 13.96, 14.25, 14.52, 14.76, 14.98 ... 16.77 | ctrl=unet | final SSIM 0.3278 | final LPIPS 0.4898\n",
      "[ep 02] β_train=0.310 K_train=6 | loss 0.1533 | train PSNR 14.36 dB | eval PSNR 1..30: 14.03, 14.38, 14.71, 15.01, 15.30 ... 18.01 | ctrl=unet | final SSIM 0.4168 | final LPIPS 0.3845\n",
      "[ep 03] β_train=0.340 K_train=7 | loss 0.1458 | train PSNR 14.59 dB | eval PSNR 1..30: 14.07, 14.47, 14.84, 15.19, 15.51 ... 18.86 | ctrl=unet | final SSIM 0.4829 | final LPIPS 0.3219\n",
      "[ep 04] β_train=0.370 K_train=8 | loss 0.1426 | train PSNR 14.71 dB | eval PSNR 1..30: 14.08, 14.51, 14.91, 15.29, 15.65 ... 19.43 | ctrl=unet | final SSIM 0.5188 | final LPIPS 0.2812\n",
      "[ep 05] β_train=0.400 K_train=9 | loss 0.1399 | train PSNR 14.81 dB | eval PSNR 1..30: 14.14, 14.60, 15.04, 15.45, 15.84 ... 19.91 | ctrl=unet | final SSIM 0.5318 | final LPIPS 0.2566\n",
      "[ep 06] β_train=0.430 K_train=10 | loss 0.1382 | train PSNR 14.86 dB | eval PSNR 1..30: 14.16, 14.65, 15.12, 15.56, 15.98 ... 20.27 | ctrl=unet | final SSIM 0.5515 | final LPIPS 0.2377\n",
      "[ep 07] β_train=0.460 K_train=11 | loss 0.1350 | train PSNR 14.98 dB | eval PSNR 1..30: 14.16, 14.65, 15.10, 15.51, 15.89 ... 18.38 | ctrl=unet | final SSIM 0.3992 | final LPIPS 0.3513\n",
      "[ep 08] β_train=0.490 K_train=12 | loss 0.1317 | train PSNR 15.11 dB | eval PSNR 1..30: 14.18, 14.70, 15.17, 15.61, 16.01 ... 18.34 | ctrl=unet | final SSIM 0.4163 | final LPIPS 0.3302\n",
      "[ep 09] β_train=0.520 K_train=13 | loss 0.1330 | train PSNR 15.06 dB | eval PSNR 1..30: 14.21, 14.74, 15.22, 15.66, 16.05 ... 18.01 | ctrl=unet | final SSIM 0.4217 | final LPIPS 0.3250\n",
      "[ep 10] β_train=0.550 K_train=14 | loss 0.1294 | train PSNR 15.18 dB | eval PSNR 1..30: 14.24, 14.80, 15.33, 15.82, 16.27 ... 18.87 | ctrl=unet | final SSIM 0.4209 | final LPIPS 0.3372\n",
      "[ep 11] β_train=0.580 K_train=15 | loss 0.1308 | train PSNR 15.16 dB | eval PSNR 1..30: 14.26, 14.85, 15.40, 15.91, 16.38 ... 18.91 | ctrl=unet | final SSIM 0.4446 | final LPIPS 0.3284\n",
      "[ep 12] β_train=0.600 K_train=16 | loss 0.1278 | train PSNR 15.25 dB | eval PSNR 1..30: 14.28, 14.86, 15.40, 15.89, 16.32 ... 17.45 | ctrl=unet | final SSIM 0.3720 | final LPIPS 0.4001\n",
      "[ep 13] β_train=0.600 K_train=17 | loss 0.1274 | train PSNR 15.26 dB | eval PSNR 1..30: 14.21, 14.74, 15.22, 15.64, 15.99 ... 16.41 | ctrl=unet | final SSIM 0.3145 | final LPIPS 0.4255\n",
      "[ep 14] β_train=0.600 K_train=18 | loss 0.1281 | train PSNR 15.25 dB | eval PSNR 1..30: 14.27, 14.85, 15.39, 15.88, 16.33 ... 18.11 | ctrl=unet | final SSIM 0.4246 | final LPIPS 0.3207\n",
      "[ep 15] β_train=0.600 K_train=19 | loss 0.1315 | train PSNR 15.13 dB | eval PSNR 1..30: 14.20, 14.72, 15.20, 15.63, 16.01 ... 17.24 | ctrl=unet | final SSIM 0.3802 | final LPIPS 0.3860\n",
      "[ep 16] β_train=0.600 K_train=20 | loss 0.1261 | train PSNR 15.32 dB | eval PSNR 1..30: 14.27, 14.85, 15.39, 15.88, 16.31 ... 17.65 | ctrl=unet | final SSIM 0.4055 | final LPIPS 0.3178\n",
      "[ep 17] β_train=0.600 K_train=20 | loss 0.1287 | train PSNR 15.24 dB | eval PSNR 1..30: 14.26, 14.83, 15.34, 15.79, 16.18 ... 16.74 | ctrl=unet | final SSIM 0.3419 | final LPIPS 0.4224\n",
      "[ep 18] β_train=0.600 K_train=20 | loss 0.1333 | train PSNR 15.06 dB | eval PSNR 1..30: 14.26, 14.82, 15.34, 15.82, 16.25 ... 17.68 | ctrl=unet | final SSIM 0.3865 | final LPIPS 0.3533\n",
      "[ep 19] β_train=0.600 K_train=20 | loss 0.1282 | train PSNR 15.24 dB | eval PSNR 1..30: 14.24, 14.80, 15.33, 15.81, 16.24 ... 17.95 | ctrl=unet | final SSIM 0.4032 | final LPIPS 0.3785\n",
      "[ep 20] β_train=0.600 K_train=20 | loss 0.1304 | train PSNR 15.15 dB | eval PSNR 1..30: 14.27, 14.85, 15.38, 15.86, 16.28 ... 17.24 | ctrl=unet | final SSIM 0.3640 | final LPIPS 0.3983\n",
      "[ep 21] β_train=0.600 K_train=20 | loss 0.1319 | train PSNR 15.11 dB | eval PSNR 1..30: 14.18, 14.70, 15.18, 15.61, 16.00 ... 17.34 | ctrl=unet | final SSIM 0.3789 | final LPIPS 0.3512\n",
      "[ep 22] β_train=0.600 K_train=20 | loss 0.1303 | train PSNR 15.16 dB | eval PSNR 1..30: 14.26, 14.84, 15.39, 15.89, 16.36 ... 18.25 | ctrl=unet | final SSIM 0.4165 | final LPIPS 0.3135\n",
      "[ep 23] β_train=0.600 K_train=20 | loss 0.1322 | train PSNR 15.10 dB | eval PSNR 1..30: 14.23, 14.79, 15.31, 15.77, 16.18 ... 17.27 | ctrl=unet | final SSIM 0.3906 | final LPIPS 0.3545\n",
      "[ep 24] β_train=0.600 K_train=20 | loss 0.1303 | train PSNR 15.16 dB | eval PSNR 1..30: 14.25, 14.81, 15.34, 15.80, 16.22 ... 17.02 | ctrl=unet | final SSIM 0.3446 | final LPIPS 0.3914\n",
      "[ep 25] β_train=0.600 K_train=20 | loss 0.1284 | train PSNR 15.22 dB | eval PSNR 1..30: 14.25, 14.79, 15.27, 15.67, 16.01 ... 15.95 | ctrl=unet | final SSIM 0.3156 | final LPIPS 0.4422\n",
      "[ep 26] β_train=0.600 K_train=20 | loss 0.1335 | train PSNR 15.04 dB | eval PSNR 1..30: 14.26, 14.82, 15.34, 15.81, 16.22 ... 17.10 | ctrl=unet | final SSIM 0.3554 | final LPIPS 0.4184\n",
      "[ep 27] β_train=0.600 K_train=20 | loss 0.1323 | train PSNR 15.09 dB | eval PSNR 1..30: 14.24, 14.80, 15.30, 15.76, 16.16 ... 16.98 | ctrl=unet | final SSIM 0.3434 | final LPIPS 0.4067\n",
      "[ep 28] β_train=0.600 K_train=20 | loss 0.1324 | train PSNR 15.07 dB | eval PSNR 1..30: 14.26, 14.80, 15.27, 15.69, 16.03 ... 16.17 | ctrl=unet | final SSIM 0.3253 | final LPIPS 0.4726\n",
      "[ep 29] β_train=0.600 K_train=20 | loss 0.1302 | train PSNR 15.15 dB | eval PSNR 1..30: 14.25, 14.79, 15.26, 15.68, 16.04 ... 16.54 | ctrl=unet | final SSIM 0.3379 | final LPIPS 0.4704\n",
      "[ep 30] β_train=0.600 K_train=20 | loss 0.1325 | train PSNR 15.06 dB | eval PSNR 1..30: 14.25, 14.82, 15.33, 15.78, 16.17 ... 16.72 | ctrl=unet | final SSIM 0.3394 | final LPIPS 0.4422\n",
      "[plot] saved step-wise psnr (eval) → runs/inpainting/nftm_unet/psnr_curve.png\n",
      "[plot] saved step-wise ssim (eval) → runs/inpainting/nftm_unet/ssim_curve.png\n",
      "[plot] saved step-wise lpips (eval) → runs/inpainting/nftm_unet/lpips_curve.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/users/balazsk/.conda/envs/nftm/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `Kernel Inception Distance` will save all extracted features in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[viz] saved per-epoch progression → runs/inpainting/nftm_unet/final/progress_epoch_final.png\n",
      "[gif] saved reconstruction GIF (GT top row, recon bottom) → runs/inpainting/nftm_unet/final/progress_epoch_final.gif\n",
      "[done] checkpoints and plots saved under: runs/inpainting/nftm_unet | controller=unet\n",
      "[metrics] saved metrics.json & psnr_curve.npy in runs/inpainting/nftm_unet | controller=unet\n",
      "\n",
      "[stage] nftm_pyramid\n",
      ">>> /gpfs/users/balazsk/.conda/envs/nftm/bin/python3 /gpfs/workdir/balazsk/NFTM/image_inpainting.py --controller dense --save_dir out_celebahq64/nftm_dense_pyramid --epochs 30 --K_train 20 --K_eval 30 --seed 0 --device cuda --save_metrics --train_dataset celebahq --benchmark celebahq --img_size 64 --pyramid 16,32,64 --pyr_steps 3,10,17\n",
      "[stage] nftm_pyramid completed in 7295.9s\n",
      "\n",
      "[stage] train_unet\n",
      ">>> /gpfs/users/balazsk/.conda/envs/nftm/bin/python3 /gpfs/workdir/balazsk/NFTM/nftm_inpaint/train_unet.py --epochs 20 --batch_size 256 --lr 0.002 --weight_decay 0.0001 --tv_weight 0.01 --seed 0 --save_dir out_celebahq64/unet --base 10 --target_params 46375 --num_workers 2 --device cuda --benchmark celebahq --img_size 64 --train_dataset celebahq\n",
      "[stage] train_unet completed in 2453.9s\n",
      "\n",
      "[stage] eval_unet\n",
      ">>> /gpfs/users/balazsk/.conda/envs/nftm/bin/python3 /gpfs/workdir/balazsk/NFTM/nftm_inpaint/eval_unet.py --ckpt out_celebahq64/unet/ckpt.pt --batch_size 256 --num_workers 2 --seed 0 --save_dir out_celebahq64/unet_eval --device cuda --benchmark celebahq --img_size 64\n",
      "[stage] eval_unet completed in 72.0s\n",
      "\n",
      "[stage] tvl1_baseline\n",
      ">>> /gpfs/users/balazsk/.conda/envs/nftm/bin/python3 -m baselines.inpainting.tvl1_baseline --iters 250 --lam 80.0 --tvw 0.1 --tau_p 0.25 --tau_d 0.25 --batch_size 256 --num_workers 2 --seed 0 --save_dir out_celebahq64/tvl1 --device cuda --benchmark celebahq --img_size 64\n",
      "[stage] tvl1_baseline completed in 36.2s\n",
      "\n",
      "[stage] nftm\n",
      ">>> /gpfs/users/balazsk/.conda/envs/nftm/bin/python3 /gpfs/workdir/balazsk/NFTM/image_inpainting.py --save_metrics --save_dir out_celebahq64/nftm --train_dataset celebahq --benchmark celebahq --img_size 64 --epochs 20 --device cuda\n",
      "[stage] nftm completed in 2141.1s\n",
      "\n",
      "[stage] nftm_dense\n",
      ">>> /gpfs/users/balazsk/.conda/envs/nftm/bin/python3 /gpfs/workdir/balazsk/NFTM/image_inpainting.py --controller dense --save_dir runs/inpainting/nftm_dense --epochs 30 --K_train 20 --K_eval 30 --seed 0 --device cuda --save_metrics --train_dataset celebahq --benchmark celebahq --img_size 64\n",
      "[stage] nftm_dense completed in 2594.7s\n",
      "\n",
      "[stage] nftm_unet\n",
      ">>> /gpfs/users/balazsk/.conda/envs/nftm/bin/python3 /gpfs/workdir/balazsk/NFTM/image_inpainting.py --controller unet --save_dir runs/inpainting/nftm_unet --epochs 30 --K_train 20 --K_eval 30 --seed 0 --device cuda --save_metrics --train_dataset celebahq --benchmark celebahq --img_size 64\n",
      "[stage] nftm_unet completed in 1878.2s\n",
      "[info] summary written to out_celebahq64/summary.json\n",
      "\n",
      "RESULTS\n",
      "method | psnr_all | psnr_miss | ssim_all | ssim_miss | lpips_all | lpips_miss | fid     | kid    | params    \n",
      "-------+----------+-----------+----------+-----------+-----------+------------+---------+--------+-----------\n",
      "unet   | 27.2716  | 24.3384   | 0.8685   | 2.2602    | 0.0434    | 0.1049     | 51.1562 | 0.0550 | 46479.0000\n",
      "tvl1   | 26.6880  | 22.7854   | 0.9074   | 0.9108    | 0.0335    | 0.0631     | 27.1260 | 0.0244 | -         \n",
      "nftm   | 20.2527  | 16.3687   | 0.5929   | 1.7941    | 0.2077    | 0.3886     | 98.3346 | 0.1079 | 46375.0000\n",
      "[info] NFTM summary written to runs/inpainting/summary.csv\n",
      "\n",
      "NFTM SUMMARY\n",
      "controller | psnr_all | psnr_miss | ssim_all | ssim_miss | lpips_all | lpips_miss | fid      | kid    | final_psnr\n",
      "-----------+----------+-----------+----------+-----------+-----------+------------+----------+--------+-----------\n",
      "dense      | 16.0266  | 12.1357   | 0.3147   | 1.3564    | 0.4753    | 0.8317     | 234.9823 | 0.2641 | 16.0243   \n",
      "unet       | 16.7221  | 12.8312   | 0.3393   | 1.3867    | 0.4427    | 0.7763     | 223.0387 | 0.2431 | 16.7206   \n"
     ]
    }
   ],
   "source": [
    "runs = {\n",
    "    \"celebahq_64\": {\n",
    "        \"cmd\": [\n",
    "            \"python3\", \"../drivers/run_all_inpainting.py\", \"--include_nftm\",\n",
    "            \"--train_dataset\", \"celebahq\",\n",
    "            \"--benchmark\", \"celebahq\",\n",
    "            \"--img_size\", \"64\",\n",
    "            \"--out\", \"out_celebahq64\"\n",
    "        ],\n",
    "        \"summary_path\": \"out_celebahq64/summary.json\",\n",
    "    }}\n",
    "\n",
    "for name, info in runs.items():\n",
    "    print(f\"\\n=== Running experiment: {name} ===\")\n",
    "    try:\n",
    "        subprocess.run(info[\"cmd\"], check=True)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\" Experiment {name} failed with exit code {e.returncode}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403bbccd-ac19-45f5-9e0a-0a62360d8436",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1abfa5-af00-42cb-8b48-ba082da6f20d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafdc302-5b32-43bc-918a-0a82b9c34275",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff40a3e-50f9-4cf4-b71d-9851e6b40e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_metrics(exp_name, summary):\n",
    "    \"\"\"Create metric comparison plots for all models in a summary.json.\"\"\"\n",
    "\n",
    "    # Extract model names except meta\n",
    "    models = [m for m in summary.keys() if m != \"meta\"]\n",
    "\n",
    "    # Enforce consistent order when present\n",
    "    order = [\"unet\", \"tvl1\", \"nftm\", \"dense\", \"unet_controller\"]\n",
    "    models = sorted(models, key=lambda m: order.index(m) if m in order else 999)\n",
    "\n",
    "    # Metrics to display\n",
    "    metrics = [\"psnr_all\", \"ssim_all\", \"lpips_all\", \"fid\", \"kid\"]\n",
    "\n",
    "    # Plot each metric separately\n",
    "    for metric in metrics:\n",
    "        values = []\n",
    "        labels = []\n",
    "\n",
    "        for m in models:\n",
    "            val = summary[m].get(metric)\n",
    "            if val is not None:\n",
    "                values.append(val)\n",
    "                labels.append(m)\n",
    "\n",
    "        if not values:\n",
    "            continue\n",
    "\n",
    "        plt.figure(figsize=(7, 4))\n",
    "\n",
    "        # LPIPS/FID/KID -> lower is better, use inverted coloring\n",
    "        color = \"tab:red\" if metric in [\"lpips_all\", \"fid\", \"kid\"] else \"tab:blue\"\n",
    "        \n",
    "for name, summary in results.items():\n",
    "    print(f\"\\n### Visualizing: {name} ###\")\n",
    "    plot_metrics(name, summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python-NFTM-kernel",
   "language": "python",
   "name": "nftm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
